{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS541: Applied Machine Learning, Spring 2025, Lab 8\n",
        "\n",
        "Lab 8 is an exercise that explores Convolutional Neural Networks (CNNs). Convolutional Neural Network (CNN) is the extended version of artificial neural networks (ANN) which is predominantly used to extract the feature from the grid-like matrix dataset. For example visual datasets like images or videos where data patterns play an extensive role. They utilize layers like convolutional layers, transposed convolution layers and pooling layers. They can perform tasks such as semantic segmentation, instance segmentation, image classification and detection and to name a few.\n",
        "\n",
        "**Lab Grading**\n",
        "\n",
        "Labs are hands-on exercises designed to provide guided experience in key concepts through this class.  You are graded based on in-lab participation (not correctness), and **are required to submit** your lab work after class, before Friday of that week.  *Make sure you fill out the attendence form before leaving class*.\n",
        "\n",
        "For students who miss a lab, you can submit a make-up lab on gradescope by the Friday directly following the lab for partial credit.  Please see the syllabus for the lab grading policy."
      ],
      "metadata": {
        "id": "k-vXIF8DpQIj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2fo-Vyv1Ycg",
        "outputId": "e3af5bee-ff97-4af7-c106-1b7290b5be5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/projectnb/ivc-ml/kmn5409/environments/sem/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "import time\n",
        "\n",
        "import torchvision.models as models # contains a lot of pretrained models you can use.\n",
        "# https://pytorch.org/vision/stable/models.html\n",
        "\n",
        "from torchvision.models import resnet50, ResNet50_Weights, resnet18, ResNet18_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFq-2PeDuwGS",
        "outputId": "ac65cb89-13ae-4078-9d86-8e545b5621e8",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                       Version\n",
            "----------------------------- ------------------\n",
            "absl-py                       2.1.0\n",
            "accelerate                    0.23.0\n",
            "aiofiles                      23.2.1\n",
            "altair                        5.2.0\n",
            "antlr4-python3-runtime        4.9.3\n",
            "anyio                         4.2.0\n",
            "appdirs                       1.4.4\n",
            "argon2-cffi                   23.1.0\n",
            "argon2-cffi-bindings          21.2.0\n",
            "arrow                         1.3.0\n",
            "asttokens                     2.4.1\n",
            "async-lru                     2.0.4\n",
            "attrs                         23.2.0\n",
            "babel                         2.16.0\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.12.3\n",
            "black                         21.4b2\n",
            "bleach                        6.1.0\n",
            "cachetools                    5.3.2\n",
            "certifi                       2024.2.2\n",
            "cffi                          1.17.1\n",
            "charset-normalizer            3.3.2\n",
            "cityscapesScripts             2.2.2\n",
            "click                         8.1.7\n",
            "cloudpickle                   3.0.0\n",
            "coloredlogs                   15.0.1\n",
            "comm                          0.2.2\n",
            "contourpy                     1.1.1\n",
            "cycler                        0.12.1\n",
            "Cython                        3.0.2\n",
            "debugpy                       1.8.7\n",
            "decorator                     5.1.1\n",
            "deepspeed                     0.10.3\n",
            "defusedxml                    0.7.1\n",
            "detectron2                    0.6\n",
            "diffdist                      0.1\n",
            "docker-pycreds                0.4.0\n",
            "einops                        0.7.0\n",
            "exceptiongroup                1.2.0\n",
            "executing                     2.1.0\n",
            "fastapi                       0.109.2\n",
            "fastjsonschema                2.20.0\n",
            "ffmpeg                        1.4\n",
            "ffmpy                         0.3.1\n",
            "filelock                      3.13.1\n",
            "fonttools                     4.48.1\n",
            "fqdn                          1.5.1\n",
            "fsspec                        2024.2.0\n",
            "ftfy                          6.1.1\n",
            "future                        0.18.3\n",
            "fvcore                        0.1.5.post20221221\n",
            "gitdb                         4.0.11\n",
            "GitPython                     3.1.41\n",
            "google-auth                   2.27.0\n",
            "google-auth-oauthlib          1.0.0\n",
            "gradio                        3.42.0\n",
            "gradio_client                 0.5.0\n",
            "grpcio                        1.60.1\n",
            "h11                           0.14.0\n",
            "hjson                         3.1.0\n",
            "httpcore                      1.0.2\n",
            "httpx                         0.26.0\n",
            "huggingface-hub               0.17.3\n",
            "humanfriendly                 10.0\n",
            "hydra-core                    1.3.2\n",
            "idna                          3.6\n",
            "imageio                       2.33.1\n",
            "importlib-metadata            7.0.1\n",
            "importlib-resources           6.1.1\n",
            "infinibatch                   0.1.1\n",
            "iopath                        0.1.9\n",
            "ipykernel                     6.29.5\n",
            "ipython                       8.12.3\n",
            "isoduration                   20.11.0\n",
            "jedi                          0.19.1\n",
            "Jinja2                        3.1.3\n",
            "joblib                        1.3.2\n",
            "json-tricks                   3.17.3\n",
            "json5                         0.9.25\n",
            "jsonpointer                   3.0.0\n",
            "jsonschema                    4.21.1\n",
            "jsonschema-specifications     2023.12.1\n",
            "jupyter_client                8.6.3\n",
            "jupyter_core                  5.7.2\n",
            "jupyter-events                0.10.0\n",
            "jupyter-lsp                   2.2.5\n",
            "jupyter_server                2.14.2\n",
            "jupyter_server_terminals      0.5.3\n",
            "jupyterlab                    4.2.5\n",
            "jupyterlab_pygments           0.3.0\n",
            "jupyterlab_server             2.27.3\n",
            "kiwisolver                    1.4.5\n",
            "kornia                        0.7.0\n",
            "lazy_loader                   0.3\n",
            "llvmlite                      0.41.1\n",
            "Markdown                      3.5.2\n",
            "MarkupSafe                    2.1.5\n",
            "matplotlib                    3.7.4\n",
            "matplotlib-inline             0.1.7\n",
            "mistune                       3.0.2\n",
            "more-itertools                10.2.0\n",
            "mpi4py                        3.1.5\n",
            "mpmath                        1.3.0\n",
            "MultiScaleDeformableAttention 1.0\n",
            "mup                           1.0.0\n",
            "mypy-extensions               1.0.0\n",
            "nbclient                      0.10.0\n",
            "nbconvert                     7.16.4\n",
            "nbformat                      5.10.4\n",
            "nest-asyncio                  1.6.0\n",
            "networkx                      3.1\n",
            "ninja                         1.11.1.1\n",
            "nltk                          3.8.1\n",
            "notebook                      7.2.2\n",
            "notebook_shim                 0.2.4\n",
            "numba                         0.58.1\n",
            "numpy                         1.23.1\n",
            "nvidia-cublas-cu11            11.10.3.66\n",
            "nvidia-cublas-cu12            12.1.3.1\n",
            "nvidia-cuda-cupti-cu12        12.1.105\n",
            "nvidia-cuda-nvrtc-cu11        11.7.99\n",
            "nvidia-cuda-nvrtc-cu12        12.1.105\n",
            "nvidia-cuda-runtime-cu11      11.7.99\n",
            "nvidia-cuda-runtime-cu12      12.1.105\n",
            "nvidia-cudnn-cu11             8.5.0.96\n",
            "nvidia-cudnn-cu12             8.9.2.26\n",
            "nvidia-cufft-cu12             11.0.2.54\n",
            "nvidia-curand-cu12            10.3.2.106\n",
            "nvidia-cusolver-cu12          11.4.5.107\n",
            "nvidia-cusparse-cu12          12.1.0.106\n",
            "nvidia-nccl-cu12              2.18.1\n",
            "nvidia-nvjitlink-cu12         12.3.101\n",
            "nvidia-nvtx-cu12              12.1.105\n",
            "oauthlib                      3.2.2\n",
            "omegaconf                     2.3.0\n",
            "openai-whisper                20231117\n",
            "opencv-python                 4.8.1.78\n",
            "orjson                        3.9.13\n",
            "overrides                     7.7.0\n",
            "packaging                     23.2\n",
            "pandas                        2.0.3\n",
            "pandocfilters                 1.5.1\n",
            "parso                         0.8.4\n",
            "pathspec                      0.12.1\n",
            "pathtools                     0.1.2\n",
            "pexpect                       4.9.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        9.4.0\n",
            "pip                           23.3.1\n",
            "pkgutil_resolve_name          1.3.10\n",
            "platformdirs                  4.3.6\n",
            "portalocker                   2.8.2\n",
            "prometheus_client             0.21.0\n",
            "prompt_toolkit                3.0.48\n",
            "protobuf                      4.25.2\n",
            "psutil                        5.9.8\n",
            "ptyprocess                    0.7.0\n",
            "pure_eval                     0.2.3\n",
            "py-cpuinfo                    9.0.0\n",
            "pyarrow                       13.0.0\n",
            "pyasn1                        0.5.1\n",
            "pyasn1-modules                0.3.0\n",
            "pycocotools                   2.0.7\n",
            "pycparser                     2.22\n",
            "pydantic                      1.10.14\n",
            "pydot                         2.0.0\n",
            "pydub                         0.25.1\n",
            "Pygments                      2.18.0\n",
            "pyparsing                     3.1.1\n",
            "pyquaternion                  0.9.9\n",
            "python-dateutil               2.8.2\n",
            "python-json-logger            2.0.7\n",
            "python-multipart              0.0.9\n",
            "pytz                          2024.1\n",
            "PyWavelets                    1.4.1\n",
            "PyYAML                        6.0.1\n",
            "pyzmq                         26.2.0\n",
            "referencing                   0.33.0\n",
            "regex                         2023.10.3\n",
            "requests                      2.31.0\n",
            "requests-oauthlib             1.3.1\n",
            "rfc3339-validator             0.1.4\n",
            "rfc3986-validator             0.1.1\n",
            "rpds-py                       0.17.1\n",
            "rsa                           4.9\n",
            "safetensors                   0.4.2\n",
            "scikit-image                  0.21.0\n",
            "scikit-learn                  1.3.1\n",
            "scipy                         1.10.1\n",
            "seaborn                       0.13.2\n",
            "semantic-version              2.10.0\n",
            "Send2Trash                    1.8.3\n",
            "sentencepiece                 0.1.99\n",
            "sentry-sdk                    1.40.3\n",
            "setproctitle                  1.3.3\n",
            "setuptools                    68.2.2\n",
            "Shapely                       1.8.0\n",
            "six                           1.16.0\n",
            "smmap                         5.0.1\n",
            "sniffio                       1.3.0\n",
            "soupsieve                     2.6\n",
            "stack-data                    0.6.3\n",
            "starlette                     0.36.3\n",
            "sympy                         1.12\n",
            "tabulate                      0.9.0\n",
            "tenacity                      8.2.3\n",
            "tensorboard                   2.14.0\n",
            "tensorboard-data-server       0.7.2\n",
            "termcolor                     2.4.0\n",
            "terminado                     0.18.1\n",
            "threadpoolctl                 3.2.0\n",
            "tifffile                      2023.7.10\n",
            "tiktoken                      0.6.0\n",
            "timm                          0.4.12\n",
            "tinycss2                      1.4.0\n",
            "tokenizers                    0.14.1\n",
            "toml                          0.10.2\n",
            "tomli                         2.0.2\n",
            "toolz                         0.12.1\n",
            "torch                         2.1.0\n",
            "torchinfo                     1.8.0\n",
            "torchsummary                  1.5.1\n",
            "torchvision                   0.16.0\n",
            "tornado                       6.4.1\n",
            "tqdm                          4.66.1\n",
            "traitlets                     5.14.3\n",
            "transformers                  4.34.0\n",
            "triton                        2.1.0\n",
            "types-python-dateutil         2.9.0.20241003\n",
            "typing                        3.7.4.3\n",
            "typing_extensions             4.9.0\n",
            "tzdata                        2023.4\n",
            "uri-template                  1.3.0\n",
            "urllib3                       2.2.0\n",
            "uvicorn                       0.27.1\n",
            "vision-datasets               0.2.2\n",
            "wandb                         0.15.12\n",
            "wcwidth                       0.2.13\n",
            "webcolors                     24.8.0\n",
            "webencodings                  0.5.1\n",
            "websocket-client              1.8.0\n",
            "websockets                    11.0.3\n",
            "Werkzeug                      3.0.1\n",
            "wheel                         0.41.2\n",
            "yacs                          0.1.8\n",
            "zipp                          3.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COD1J-Ha76bB",
        "outputId": "8e255a14-3948-42fd-90d4-c947f62e0b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "# Load the CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "14w8MpcfAgMa",
        "outputId": "41450376-8fc7-4a9c-81b6-33c756c8d168",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2066it [00:03, 588.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4074it [00:07, 558.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  4000] loss: 1.863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6113it [00:10, 568.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  6000] loss: 1.751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8065it [00:14, 605.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  8000] loss: 1.670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10077it [00:17, 632.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 10000] loss: 1.616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12089it [00:20, 609.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 12000] loss: 1.559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12500it [00:21, 585.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 47.49%\n",
            "Avg time taken for prediction: 0.00028611249923706053\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define a simple CNN architecture\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 10, 7, padding=\"same\") # inchannel, outchannel, kernel size\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc3 = nn.Linear(2560, 10)  # Adjust the output classes accordingly\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x))) # this is a square output\n",
        "        x = x.view(x.shape[0], -1)  # Adjust the feature map size accordingly\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the network\n",
        "net = SimpleCNN().to(device)\n",
        "\n",
        "# Define the loss function and optimizer, we don't use momentum here\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0)\n",
        "\n",
        "# Training the network\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in tqdm.tqdm(enumerate(trainloader, 0)):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs.to(device))\n",
        "        loss = criterion(outputs, labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "avg_time = []\n",
        "for data in testloader:\n",
        "    images, labels = data\n",
        "    start = time.time()\n",
        "    outputs = net(images.to(device))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    end = time.time()\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted.cpu() == labels).sum().item()\n",
        "    time_taken = end - start\n",
        "    avg_time.append(time_taken)\n",
        "\n",
        "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total}%\")\n",
        "print(f\"Avg time taken for prediction: {np.average(avg_time)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Here we want to add momentum for our Optimizer and we can we it helps our classification results"
      ],
      "metadata": {
        "id": "aDR29xzLsbuL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpbW3BBFpGMC",
        "outputId": "b06a544b-56cc-4f68-d843-7dda0530bfe6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2097it [00:03, 594.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4104it [00:07, 583.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  4000] loss: 1.565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6113it [00:10, 585.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  6000] loss: 1.465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8089it [00:13, 587.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  8000] loss: 1.391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10106it [00:17, 588.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 10000] loss: 1.408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12066it [00:20, 587.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 12000] loss: 1.374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12500it [00:21, 583.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 54.61%\n",
            "Avg time taken for prediction: 0.0002834988594055176\n"
          ]
        }
      ],
      "source": [
        "# Initialize the network\n",
        "net = SimpleCNN().to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training the network\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in tqdm.tqdm(enumerate(trainloader, 0)):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs.to(device))\n",
        "        loss = criterion(outputs, labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "avg_time = []\n",
        "for data in testloader:\n",
        "    images, labels = data\n",
        "    start = time.time()\n",
        "    outputs = net(images.to(device))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    end = time.time()\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted.cpu() == labels).sum().item()\n",
        "    time_taken = end - start\n",
        "    avg_time.append(time_taken)\n",
        "\n",
        "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total}%\")\n",
        "print(f\"Avg time taken for prediction: {np.average(avg_time)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXGDzrMjCBKK"
      },
      "source": [
        "## Let's visualize what the filters are learning for our task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Xk22ots0mUx",
        "outputId": "52ce9e4b-a558-4a91-cf31-395f7097821b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABcElEQVR4nO2ZPYqDYBCGN2HBC2gTI6ZLECz8KXMCS62ChXiCHMccIJWVkCMIglewFewkXUBE3C7LZIR8Cws7+zFP98AbmNdxIOBqnuf5QwLWfz3Ab8FFqMFFqMFFqCFNkU/RYJqmwHVdRxnTNIFfLheUadsWeBRFKBPHMfDj8fh2Pmk2wkWoIXwjhmEAd10XZe73O3DLslDm9baSJEGZPM+B8438R7gINYSPfbPZAH88HiijKArw6/WKMlmWAR/HEWXCMBQd64k0G+Ei1BC+kcPhAHy9xs+gKArgp9MJZZqmAe55Hsqoqio61vc8P/4FUbgINaQpInzsZVkC1zQNZYIgAH4+n1Fmv98D3+12KDMMg+hYT6TZCBehhvCN2LYNfOndrqoK+NKfP8dxgC/d2u12A77dbt/OJ81GuAg1pCkifOx1XQP3fR9lpmkC3vc9yrwed9d1bzMiSLMRLkKNFX9nJwYXoQYXoQYXoQYXocYXCKJHYMGaOaoAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABbklEQVR4nO2ZMYqDUBCGdV0RYiNJEcUjxE6rgBdInypXsMxFUuQUacXWWhAs7URrEWKnWLhdYBzBVyzs7GO+7oO/mJ9hEFWd53lWJODrrwf4LbgINbgINbgINaQp8i0afDwewKdpQhnTNIEnSYIyl8sFuKZpKHM+n4F7nrc5nzQb4SLUEL4Rx3GAh2GIMlmWAT8cDijzer2A3+93lEnTFDjfyH+Ei1BD+NjHcQTeNA3KuK4LfHnYiqIoURQBNwwDZZYPRBGk2QgXoYbwjeR5Dvx2u6HM8/kErus6yuz3e+Dv9xtlyrIE7vv+5nzSbISLUEOaIsLHfr1ega8daVVVwPu+RxnbtoHXdY0ya2+NW0izES5CDeEbKYoCuGVZKBPHMfDdbocyyzs6Ho8o03Wd6FgfpNkIF6GGNEWEj335+WftE00QBMBVVUWZ0+kEfBgGlGnbVnSsD9JshItQQ+X/7MTgItTgItTgItTgItT4Af9BTxmJUVYyAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABcUlEQVR4nO2ZoaqDcBSH3WWwbBlatiA2QZbEIu4d9gJ2l30T68KaVcPa9gBLS4LFBxCLRYTpbYOzI/gPF+7hcL72wQ93fhwOIltN0zRpDPj57wH+CilCDSlCDSlCDTZF1qrBNE2BB0GAMrfbDbhlWShzvV6BR1GEMnVdAz+fz4vzsdmIFKGG8o3sdrvFjGEYwNu2RZnT6QR8u92iTBiGqmN9YLMRKUINNkWUj900TeCO4+CHreHjsixDmaqqgHuehzKPxwN4kiSL87HZiBShhvKNbDYb4M/nE2XKsgR+v99R5nA4LP7W3EtyCTYbkSLUYFNE+dhfrxdw3/dRJs9z4N8vNk3TtL7vgc8d/+VyAT73FfkNm41IEWoo30hRFMDf7zfK6Lq++Jzj8Qi86zqU2e/3qmN9YLMRKUINNkWUjz2OY+DDMKBM0zTA577+bNsGPo4jyriuqzrWBzYbkSLUWMn/7MSQItSQItSQItSQItT4BRj0Tl94n4WeAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABeUlEQVR4nO2YMYqDUBCGN2uwiN7BgI1FbhCwlVxCj2BnJblBGgs9glWqNGlSCBZeIaAIFmkCqYKVwe2EcRZ8xcIOw3zdHz7I/IwvL7gax3H8YsD3fw/wV0gRakgRakgRarApslYVL5cLyOfzGTmu64LsOA5yTNME2TAM5OR5DnIcx4vzsdmIFKGG8hm53+8g67qOnMPhAPJms0FOXdcgJ0mCHMuyVMeaYLMRKUINNkWUD3vf9yCfTifkaJoG8uPxQE6WZSAPw7D4XSqw2YgUoYbyGdntdiD/9mzPP0vTFDnzi9W2beTs93vVsSbYbESKUINNkZXqK9OmaUD+fD7ICYIA5KqqkDP/0bjdbsiZX4jb7XZxPjYbkSLUUL4QX68XyGVZIuf5fIIchiFyPM8DuW1b5BRFAXIURYvzsdmIFKEGmyLKh33+GvP9fiPneDyC7Ps+cuaH+3q9IqfrOtWxJthsRIpQQ/lPI3XYbESKUEOKUEOKUEOKUOMHj5pmXAEzQKMAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABgklEQVR4nO2YMY6CUBCGYbOYkEhLQyWdlzBUSCkXoOIKth5AG3sjFQUVJyA2hppCG0PgBEplZcN2JMNswis22clkvu5LfuP8mbzwQO/7vtcY8PXfA/wVUoQaUoQaUoQabIp8qwZ3ux3wtm1RxrZt4FEUoYxpmsDLskSZy+UCPE3TyfnYbESKUEP5jDweD+Dr9RplVqsV8KZpUGY2mwF/Pp8o03Wd6lgDbDYiRajBpojyYdd1HbhhGChjWRbw8cHWNE07n8/AX68XyiwWC9WxBthsRIpQQ/mMbDYb4MvlEmXqugZ+OBxQZnwhDMMQZXzfVx1rgM1GpAg12BTRVT+Z3u934NfrFWXyPAdeFAXKBEEA/Hg8oozjOMDn8/nkfGw2IkWoofxArKoK+H6/n/zNb2+R40vj5/NBmSzLgMdxPPlfbDYiRajBpojyA3F82/U8D2Vc1wW+3W5R5v1+Az+dTiiTJAnw2+02OR+bjUgRaiifEeqw2YgUoYYUoYYUoYYUocYPKWBcXUR9dscAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABdklEQVR4nO2ZsYqDQBCG1+NqSZveQiFEQloLC0tbwXQBH8HKRkiTd0iZF0gRe59AQWyt7AUxjVh5XWB24LLFwQ3LfN0HfzE/w7CSGOu6rkIDvv57gL+Ci1CDi1CDi1BDmyLfqsGiKICP44gyhmH86kIIsdlsgLdtizJVVQF/PB4f59NmI1yEGso3UpYl8GVZUOZ8PgNvmgZl6roG3nUdyhwOB9Wx3mizES5CDW2KKB+7aZrA4zhGme12C1w+bCGE6Pse+DRNKGNZlupYb7TZCBehhvKNhGEI3HEclLnf78DzPEcZ+UPyeDyijG3bqmO90WYjXIQa2hRRPvbX6wX8+XyiTJZlwIdhQJkoioCfTieUkR9WFbTZCBehhvKNzPMMPE1TlNnv98A9z0OZJEmA+76PMpfLBfj1ev04nzYb4SLU0KaI8rHLP1u6rosyQRAA3+12KCM/drfbDWXkx1cFbTbCRahh8P/sxOAi1OAi1OAi1OAi1PgBRc9Q/FxSVk4AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABdElEQVR4nO2ZsYqDUBBFN0uwskgQK9FS0qQICBIwIGjnR/gLkjIK+abUKdIE7CwkaOMPWAYECwXTCZNZyCsWdvYxp7tweMxlHFJkMU3T9CUB3389wG/BRajBRajBRaghTZGlqJjnOciXywU5u90OZEVRkOP7Psi32w05VVWBnGXZx/mk2QgXoYbwjRiGAXIcx8g5nU7w8SV+/v2dKIqQY1mW6Fgz0myEi1BDmiLCx66qKshlWSInCAKQ0zRFzna7BVnTNOQ4jiM61ow0G+Ei1BC+kcfjAbLnechZrVYgHw4H5JzPZ5DX6zVy9vs9yCI3I81GuAg1pCkifOy6roPc9z1yTNMEOUkS5DRNA/Lz+UTO9XoFmY/9PyJNEeEbef9uXddFTl3XINu2jZzj8QhyURTI+elH8hPSbISLUEOaIsLHvtlsQL7f78gZxxHkMAyRMwwDyF3XIadtW9GxZqTZCBehxoL/ZycGF6EGF6EGF6EGF6HGC6sJS+bVAM3nAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABe0lEQVR4nO2YMYrCUBCG18XCkEZMI9iJTSBtmkjKYKNgY+ElUnmLYHKPXCCluUAukDIEVOw1QSHbBWZHdqdY2GGYr/vg5zE/w+OFDLqu6z4E8PnfA/wVWoQbWoQbWoQbYooMqcEsy4CnaYoyj8cDuOd5KBOGIfDT6YQyRVEAPxwOv84nZiNahBvkO1LXNfDVaoUyx+MR+Ov1Qpn5fA58MpmgTNM01LF6xGxEi3BDTBHyZbdtG/hsNkMZ3/eBJ0mCMuPxGPh+v0eZ9XpNHatHzEa0CDfId6SqKuDn8xllXNcFvlwuUSbPc+D3+x1l4jimjtUjZiNahBtiigyov0yjKALeti3K7HY74M/nE2U2mw1w0zRRJggC4O8e1u+I2YgW4Qb5QbzdbsAdx0GZ6/UKDx/i47fbLfDL5UId4UfEbESLcENMEfJln06nwN+9o2VZAl8sFihjWRZwwzBQZjQaUcfqEbMRLcIN8kcjd8RsRItwQ4twQ4twQ4tw4wvez1YniKnHngAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABfklEQVR4nO2YIauDYBSGr5cblxfcEAR/gWDezBssCLOuGI1Gm80w8CfIgn19SZCV/YQlhcGGICzYvG1wdi74XbhwD4fztEfecF4OB0VtGIbhgwGf/z3AXyFFqCFFqCFFqMGmyJdq0Pd94NPpFGXyPAe+3+9RxrZt4NfrFWUulwvwJElG52OzESlCDeUb2W63wO/3O8rM53PgURShzPvd6LqOMs/nU3WsF2w2IkWowaaI8rG/M5lM0LPVagU8TVOUOZ1OwD3PQ5nlcvnredhsRIpQQ/lG2rYF7jgOyiwWC+BVVaHM+XwGrmkaysRxrDrWCzYbkSLUYFNEU/1lWhQFcNd1UeZ2uwHvug5lwjAEbpomyhiGATzLstH52GxEilBD+YXY9z3ww+GAMpZlAd9sNigTBAHwsixR5v1PiwpsNiJFqMGmiPKxPx4P4D8dZNM0wOu6Rpn1eg18NpuhzPF4BL7b7UbnY7MRKUIN5Y9G6rDZiBShhhShhhShhhShxjcUsFb5tuxFbAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABgElEQVR4nO2YMYqDUBCGjQTS2FmniV0KQxqLHCGdfS5gYaP38AIWFh7BMopNqkDadKmsAkHBQrFQt9tlMrK+XRZ2eMzXfeEX5nd4vOBiHMdRkQD1vwf4K7gINbgINbgINaQpsvztg4/HA/2W5znw1+uFMsMwADdNE2WOxyNwVZ1/39JshItQQ/iMBEEAPE1TlCnLEvjz+UQZx3GAXy4XlFmv18B3u93sfNJshItQQ5oiwof9/VI6nU4okyQJ8KnL7nq9Avd9H2U0TRMd62u+Hz9BFC5CDeEzstlsgHddhzJVVQHPsgxlXNcFfrvdUGa1WgE3DGN2Pmk2wkWoIU2Rhegn0ziOv3VFUZTtdgs8DEOU6fse+H6/R5n3C/F8Ps/OJ81GuAg1hC/EKIqA67qOMvf7HXjTNChj2zbww+GAMlPPzSHNRrgINaQpInzYPc8D3rYtyhRFAdyyLJR5/2Q6dR/XdS061ifSbISLUEP4TyN1pNkIF6EGF6EGF6EGF6HGB1ZqYpmvt5jrAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABe0lEQVR4nO2ZMcqDQBCFNcTYp0kjeAFBsApJpeQSVl7DU9ikyyFCDmArYh8NacQmVRAE7U0XmJ2AW/zwD8O87skHO89h2Vk153meDQZa/XcBfyUJQk0ShJokCDWxCbLWBS+XC/DjOCJmu90C/3w+EbNawXd3v98RczgcgE/TdLE+Nh2RINRk6g6NURQB/3q9EHM8HoHfbDaIUffNNE2Ieb/fwHddt1gfm45IEGpiE0T7QLQsC/jz+YyY6/UKvOM4eME1XNJ1XcR4nqdb1ldsOiJBqEn7QFSHxrquEZMkCfBBECCmaRrgi6JAzOPxAD7LssX62HREglATmyDaB+LtdgM+jmPEqJNt27aIGYYB+DzPEXM6nXTL+opNRyQINWnvkf1+D3zf94hRn/1i1NufbduI+XX7XBKbjkgQamITRHv6NU0TeN/3EaN+Mg3DEDG73Q54dRo2DMOoqgr4siwX62PTEQlCTdoHIvXf8Ww6IkGoSYJQkwShJglCTR81mGf9x20Z3wAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABgUlEQVR4nO2YMauCYBSG7VIOIQ0SbQ6OLW1CIGiE4O5PcWzqP/gLcgtxV8KxybG1toi2Aich8G4XjueC33DhHg7n3R54kPNyOCiOuq7rNAb5+u8B/ipShFqkCLVIEWphU2SsKsZxDLhpGuSsVivAbdsiJ0kSwJvNBjmPxwPw6XQanI/NRqQItYxUPxoNwwAcRRFyLpcLYN/3kfP5fACXZYmc6/UKWGVENhuRItTCpojysW+3W8Cz2WzQWS6XyKnrGrBt28gpigLw4XAYnI/NRqQItSjfSFVVgF+vF3I8zwO8WCyQ836/AWdZhpwgCAD/dkf9sNmIFKEWNkWUj32/3wOez+fI6T9K13XkHI9HwJZlDT4nTdPB+dhsRIpQi/JfFNM0Abuui5zpdAr4fr8jZ71eAz6fz8jZ7XaqY/2EzUakCLWwKaJ87M/nE3D/14+madrtdgPsOA5y+i/SyWSCnDzPAYdhODgfm41IEWpR/mikHjYbkSLUIkWoRYpQixShlm+LEWrxEvoLXwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABYklEQVR4nO2ZsYqDUBBFzRolSoikT2EaK8VS/LZ8hd+gNlbmN7QUJGUsLLRQsBbdLjBOwFcs7PCY0104PN5lmET0sK7rqkjAz39f4K/gItTgItTgItSQpshRVMyyDOTz+YycoihAvt/vyOm6DuT3+40cTdNAjqJo937STISLUEN4R9I0Bdn3fXzYER7nui5yLpcLyGEYIuf5fIpe64M0E+Ei1JCmiPCyq6oK8jAMyNF1HeQ8z5HTNA3Inuchp21b0Wt9kGYiXIQawjtiWRbIcRwjZ5qm3XO2D5tJkiAnCALRa32QZiJchBrSFBFe9u1T6ul0Qs48zyBvfyAURVH6vgfZtm3kfPuz3UOaiXARagjvyPV6BfnxeCDndruB/Hq9kLMsC8h1XSOHd0QGuAg1hJe9LEuQq6pCjuM4IBuGgZxxHEE2TRM5317H7iHNRLgINQ78nZ0YXIQaXIQaXIQaXIQavz8zS9TvHkZDAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABeklEQVR4nO2ZsaqCcBSH7Vpuji1BQ0OEbYLQ0hINbq29RM/SO/QAvYKTIBiCk+AmkoObg0OoYZtw7gn8Dxfu4XC+7YMfcn4cDohO+r7vNQb8/PcAf4UUoYYUoYYUoQabIlPV4PV6Bd51HcosFgvgWZahjO/7wOfzOcrsdjvgl8tldD42G5Ei1FC+kfv9Dvx8PqPM4/EAfjqdUGa9XgO3bRtliqJQHWuAzUakCDXYFFE+9u12C/z9fqPMcrkEHkURylRVBbyua5RJ0xT44XAYnY/NRqQINZRvxHEc4EEQoMztdgP+7YWwaRrg327teDyqjjXAZiNShBpsiigf+3QKo7+PX9M0zbIs4K/XC2V0XQf+7YutYRiqYw2w2YgUoYbyjZimCXyz2aDMfr8ffc7z+QQexzHKzGYz1bEG2GxEilCDTRHlY0+SBHgYhijjeR7wtm1RZrVaAS/LEmXyPAfuuu7ofGw2IkWoMZH/7MSQItSQItSQItSQItT4AM2jV6FxGdjPAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABf0lEQVR4nO2ZsaqCYBTHP+UKNWSbFA6CTj2Br5A+hA/gQ9Rr5OIbtDkEbY4WODk0Bbk06CQ4Cd4tOJ24fsOFe+7H+W0/+CPn3+EUlTaO4ygUQP/rAX4LLkINLkINLkINZYp8yQbzPAc+DAPKlGUJfD6fo8z9fge+XC5Rpq5r4EmSTM6nzEa4CDWkb6SqKuCu66KMYRjA4zhGmdvtBtw0TZRZrVayY71QZiNchBrKFJE+dk3TgNu2jTKe5wF/PB4oc7lcgH960zifz8CjKJqcT5mNcBFqSN9I13XAd7sdyug6fF2OxyPKBEEAfDaboYxlWcD5Rv4jXIQa0se+2Wx+dCGEOJ1OwNM0RZmiKID7vo8yi8VCdqwXymyEi1BDk/1b4Xq9Am+aBmW22y3wTx+IjuMAfz6fKJNlGfDD4TA5nzIb4SLUUKaI9LGHYQi8bVuUWa/Xk895/6nn/VulEEL0fQ98v99PPleZjXARakjfCHWU2QgXoQYXoQYXoQYXocY3TDdY0C128lMAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABcklEQVR4nO2ZvYqDUBCFryEELWITQkAhYGUhSHwNX0AfJk9ma+kDWCUhYGcRETWFBLdzGWfBWVjY4TJfd+SocxzGn6sxTdOkNGDz3wX8FRKEGxKEGxKEG9oE2VKNSZIA7TgO8rzfb6CPxyPynE4noPu+R55xHIG+Xq+r9WnTEQnCDfKM1HUNtGEYyBOGIdBN06we1/M8tC3Pc2pZM9p0RIJwQ5sg5GFfPqSGYUCetm2BjqIIeR6PB9C73Q559vs9tawZbToiQbhBnpHD4QD08/lEnuUL4eVyQZ4sy4C+3+/Icz6fqWXNaNMRCcINbYKQh922baB/GvY0TYHebPB1Wq7QmqaJPEEQUMv6Ptev92CKBOEGeUZc1wW66zrkud1uQPu+jzyfzwfo5ZenUkpZlkUta0abjkgQbmgThDzsr9cL6OUXo1L4BlBVFfIsl1GLokCesiyBjuN4tT5tOiJBuGHIf3ZmSBBuSBBuSBBuSBBufAENflbeOVxcBAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABZUlEQVR4nO2ZMaqDUBBFzSeIYExpLYogmMYVWJl1WGQDrsnOfVhYWgiCNrYJimAhCIm/C4wj+IoPf3jM6Q5cZC7jJISc1nVdFQn4+e8B/gouQg0uQg0uQg1pipxFg4/HA7jjOCjTNA3wPM9Rxvd94MMwoIxpmsCzLDucT5qNcBFqCN+IZVnAt/egKIry+XyAR1GEMlVVAdc07fA5IkizES5CDWmKCB/75XIBPs8zylyvV+C2baNMURTAVVVFmb0v2yOk2QgXoYbwjQRBADxNU5TZvtu32w1luq4DPk0TynieJzrWF2k2wkWoIU0R4WPfHuDr9UIZ13WB3+93lOn7/vA5SZKIjvVFmo1wEWoI34hhGMB1XUeZZVmAv99vlAnDEHhd13ios/BYX6TZCBehhjRFhK+qLEvgz+cTZeI4Bj6OI8q0bQt875fm3gfJEdJshItQ48T/sxODi1CDi1CDi1CDi1DjFxXlVA4YS/UiAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABgElEQVR4nO2YMY6CUBCGn2aJ0QIxgcROgcKClgRquYwHQY9B7L2BhY2UnICCHgItFBRsx2YYsvs22WQnL/N1X/Kr8zs+FRbDMAxCAZb/PcBfwUWowUWowUWooUyRD9lgHMfA1+s1yvR9D/z1eqHM+XwGbpomyqRpCvx+v/84nzIb4SLUkD4juq4D3263KNO2LfDdbocyRVEAz/McZQ6Hg+xYI8pshItQQ5ki0oe9rmvgXdehzGazAe66Lsq832/ghmGgjO/7smONKLMRLkIN6TPieR7wJElQJooi4MfjEWUejwfwMAxRxrIs2bFGlNkIF6GGMkUWsrdMq6oCfjqdUOZyuQC/Xq8oEwQB8OUSv5e32w349EtkDmU2wkWoIf2DOL0inF4NCiFE0zTA5z7/WZYBn7sbY9u27Fhfr/XrRxCFi1BDmSLSh/35fALf7/co4zgO8OmPqBBCrFYr4JqmoUxZlt8+7xzKbISLUEP6TyN1lNkIF6EGF6EGF6EGF6HGJ/h9S6HNnCNSAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABg0lEQVR4nO2YocqDYBSGv/3sChYXBwbX1ncBYnHFS7CZZMUyxtosYl5Zk4EX4A1oEYuGhcXFBdNgrLg2OJ4f/MIP/+FwnvbA68d5ObhvOOn7vlcM+PnvAf4KKUINKUINKUINNkWmusE8z4Ffr1eUud1uo+eUZQl8vV6jzOPxAH65XEbPZbMRKUIN7XdksVgAtywLZeI4Bp5lGcq0bQv8fr+jTJIkumN9YbMRKUINNkW0X/YgCICfTieUGf4gHA4HlNnv98CbpkGZ5/OpO9YXNhuRItSY6H5Fmc1mwM/nM8rUdQ18+EdTKaVs2wa+Wq1Q5ng8Ai+KYnQ+NhuRItRgU0T7QtxsNsAdx0GZKIqAb7dblAnDELjv+yjz29ljsNmIFKGG9oW42+2Am6aJMq/XC7hhGCjzfr+BDy9apZTyPA94VVWj87HZiBShBpsi2hficrmED07xo8NPO67rokzXdcDn8znKpGmqO9YXNhuRItTQvhCpw2YjUoQaUoQaUoQaUoQaH5yPYLxBFherAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABfUlEQVR4nO2XMYqDUBCGN0sKD5DGCwRMSBNsPEYCqSSl5AIpPEIgOYGF9oJdehutLAI2YhkkENKktNPthHEWMsXCDsN83Q9fcH6Gx3uZ9H3ffwng+78H+Cu0CDe0CDe0CDfEFJlSxSRJQD6fz8hZLBYgp2mKnM1mA/Lr9ULO+HePx+PjfGI2okW4QT4j1+sV5MvlgpwwDEG+3+/4g1P4ydvthpzdbkcda0DMRrQIN8QUmVD/Ie73e5ANw0CO53kgx3GMnKIoQHZdFzmHwwFkyohiNqJFuEG+EOfzOciz2Qw5bduCbJomck6nE8hZliEniiLqWANiNqJFuCGmCPlCXC6XIB+PR+Q8n0+QV6sVct7vN8hd1yEnz3OQgyD4OJ+YjWgRbpAvRN/3Qa7rGjnjh+Rvx89xHJCrqkKObdvUsQbEbESLcENMEfJhH79kLctCzvjiWq/XyCnLEuTtdoucpmmoYw2I2YgW4Qb50cgdMRvRItzQItzQItzQItz4Ab2VY8IP4UEbAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABb0lEQVR4nO2YPaqDUBBGX+JrQrSwSCWBWLkNsbCycTFZRPYScAtWrsAqINYqSCD+EzBdYBwhl/DgDcOc7guHcL8Mw41u5nmefxiw/e8D/BVShBpShBpShBpsivyqikmSgDwMA3LiOAbZsizkZFkGsu/7yNlu4e/red7H87GZiBShxubbP4232w19No4jyPf7HTl934Os6zpymqYBeW2PlrCZiBShBpsiyhdiFEUgt22LnOPxCPLj8UDOfr8Hua5r5EzTpHqsN2wmIkWoobwjmqaB3HUdcvI8B9m2beQcDgeQi6JAzul0Uj3WGzYTkSLUYFNEednTNAXZNE3kLC/EtUVePv1VVYWcte/+BJuJSBFqKD8hOo4DchiGyCnLEuQgCJCzvEjXduT5fIJ8Pp8/no/NRKQINdgUUb4Ql68/L5cLclzXBfl6vSJnuey73Q45hmGoHusNm4lIEWp8/cqUGmwmIkWoIUWoIUWoIUWo8QJoK2IkhqKmkgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABd0lEQVR4nO2YMYqDUBCG101Ki2AbUtlFEFLmAhK8QA6gkFZ7wRN4AcEyFim0s/UM6cXCJgcwCKncLjBvAj6WhR2G+bpfPmR+hocPjXme5y8GfP/3AH+FFKGGFKGGFKEGmyJrXdHzPJDP5zNyhmEAuSxL5ARBAPJ2u0VOXdcgV1W1OB+bjUgRamifkXEcQX48Hsg5HA4gN02DnM1mA3LbtsixLEt3rDdsNiJFqMGmiPZhd10X5Ov1ipyiKECO4xg5q9UK5OfziZxpmnTHesNmI1KEGobuX5T7/Q5yGIbIsW0bvtwwkNN1Hci+7yPndDqBfDweF+djsxEpQg02RbQPu0qe5+jZ5XIBOYoi5Oz3e5A/ffzUm3aSJIvzsNmIFKGG9qVR/SilaYoc9SKp/lX59J7b7Yac1+ulO9YbNhuRItRgU0T7sJumCXLf98hRfwftdjvkZFkGsuM4yFFvvzqw2YgUocavL43UYLMRKUINKUINKUINKUKNH7cLWqSoQdbpAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABhUlEQVR4nO2XMauCYBSGr5c7S4OTCIFQS9B/cAwEF5eGNhd/QmuLDRESDebkpmt/oN32thZxEqx/EN5NOJ3Ab7hwD4fzbA+8yHk5HPDTuq7rvhjw/d8D/BVShBpShBpShBpsivyoBo/HI3Bd11FG0zTgaZqiTBAEwKfTKcrkeQ78cDgMzsdmI1KEGso3cr/fgfu+jzKj0Qj4ZDJBmbZtgVuWhTLz+Vx1rB42G5Ei1GBTRFN9Ia5WK+CPxwNl4jgGbts2ymy3W+Cz2Qxlzucz8CzLBudjsxEpQg3lGynLEvh+v0cZx3GA3243lKmqCvhisUAZz/OAm6Y5OB+bjUgRarAponzs70c6Ho/xx95eiMvlEmXCMAT+6aVZFAXwKIoG52OzESlCDeUX4m63A75er1EmSRLghmGgTNM0wC+XC8q8Xi/VsXrYbESKUINNEeVjv16vwD/9tW42G+B1XaPM6XQC7rouyjyfT9WxethsRIpQQ/mnkTpsNiJFqCFFqCFFqCFFqPELS+VgBc6U2IEAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABfElEQVR4nO2YPaqDUBBGzSMuIykCFtoEBAmBpHANKYxVNpHYpFPIAkxhY+UiLLIRC21SiUUqK0EwnTDOg1zCgzcMc7pPPmQOw8Wf2TAMg8aAn/8e4K8QEWqICDVEhBpsROaqxfP5DLKu66iz3+9B9jwPdeI4Bnm326FOFEUgZ1n2cT42GxERaiifkdfrBfJ2u0WdxWIBsu/7qOO6Lsi32w11TNNUHWuEzUZEhBpsRJQPu23bICdJgjrTB+BvB/lyuYBcliXqrFYr1bFG2GxERKihfEa6rgO5rmvUuV6vID+fT9QxDAPkvu9RZ7PZqI41wmYjIkINNiKzb3+ZFkWBrlmWBXIQBKgz/YqcvjFrmqalaQry/X7/OA+bjYgINZQfiI7jgByGIepM/7S0bYs66/Ua5MfjgTpVVamONcJmIyJCDTYiyoe9aRqQ8zxHncPhAG8+x7c/Ho8gL5dL1DmdTqpjjbDZiIhQ4+uXRmqw2YiIUENEqCEi1BARarwBMXhRFJ0bxckAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABeElEQVR4nO2YMaqDUBBF9RNcQRobG1NJ0FSSMqWNiI2Y0jLLCCFNduBCLCQLsAmCZWJrk04QbP2dMBkhr/jwh2FOd+AWcxme7yX6NE2TxoCf/x7gr5Ai1JAi1JAi1GBTZKUaPJ/PwJ/PJ8q0bQt8t9uhTBzHwN/vN8pkWaY61gybjUgRauiqj8bNZgP8cDigjG3bwF+vF8qkaQrccRyUqaoKeJIkX+djsxEpQg02RZQvRMuygD8eD5QpigL4er1Gmc8PwjiOKBNFkepYM2w2IkWooXwh6roO/HK5oEzXdcB930eZ4/EI/H6/o4xhGMCDIPg6H5uNSBFqsCmifCGeTifgruuizO12A77dblEmz3PgnuehTN/3qmPNsNmIFKGG8hmp6xr40oPwer0CL8sSZUzTBD4MA8os/fvyDTYbkSLUYFNE+bDv93vgSxfZ5+H+fOlqGj7cTdOgTBiGqmPNsNmIFKGG8i9E6rDZiBShhhShhhShhhShxi/zOFVtrS6C6AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABfklEQVR4nO2YMYqDUBCGx3UhCMkBElJqY5EUpgvExiKllY0n8AhCDmGVk4TcIFV6LyBKQkiXTsTthHGWzWNZ2GGYr/vgL+ZneDho9X3fgwA+/nuAv0KLcEOLcEOLcENMkU/ToGVZyPf7PclMJhPkq9WKZKqqQh7HMcl4nofc9/2384nZiBbhhvEbcRwHeZZlJHM8HpFHUUQyl8sFuW3bJPN4PEzHGhCzES3CDTFFjB/7drtFfr1eSWaz2SC/3W4kcz6fkX/3sLuuQx6G4dv5xGxEi3Dj10djXdckM3434wMRAGA2myHf7XYks16vTccaELMRLcINMUUs01+m0+kUeZqmJNO2LfLlckky8/kc+fP5JJnxRZzn+dv5xGxEi3DD+IOYJAny8fEHAFAUBfLx8QcAcL/fkR8OB5I5nU6mYw2I2YgW4YaYIsaPvWka5EEQkExZlsgXiwXJvF6vHx0AwHVd07EGxGxEi3DD+GjkjpiNaBFuaBFuaBFuaBFufAHC/lbbvenoxQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABfUlEQVR4nO2ZMaqDUBBFX35SpRA3kGAhWUAKI4gprSzdgqVV9pAVZBHpdA02wVIQsRVEYhNMkU7wd8I4Ql7x4Q+POd2BW8xlGHwkq3EcR6EAP/89wF/BRajBRajBRaihTJGNbNA0TeD7/R5lwjAEbts2yjweD+Cv1wtl2rYFfr1ev86nzEa4CDWkb8TzPOBxHKPM8XgEXlUVyqRpClzTNJTZ7XayY00osxEuQg1likgfe1mWwN/vN8p8Ph/gWZahjOM4wIdhQJn7/Q48iqKv8ymzES5CDekb6boOuOu6KKPrOvDL5YIyt9sNeBAEKJMkiexYE8pshItQQ5ki0sf+fD6BL71s57++Ln00LcsCPn8NCyHE+XyWHWtCmY1wEWpI38jpdALu+z7KrNdr4Eu/kNR1DbwoCpTJ8xz40od1jjIb4SLUUKaI9LE3TQP8cDigjGEYwJdesX3fA5+/qoUQYrvdyo41ocxGuAg1Vvw/OzG4CDW4CDW4CDW4CDV+AbHGX5MkusBeAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABb0lEQVR4nO2ZMaqDUBBFjQQkhcQyoCBkByIBKzcgKXQJ2VrKLMAliIWWgo1C0mohJpAi4u8+jBPwFR/+MMzpLpzAuxkmT8xmnudZY4D+3wf4K6QINaQINaQINdgU2aqKl8sF5LZtkWPbNsjn8xk5u90O5OfziZw0TUG+Xq+r52MzESlCDeUdMU0T5CiKkBMEAcin0wk5hmGA3Pc9chzHUT3WL2wmIkWowaaI8rIvLzLf95GzvNzKskTOOI4g13WNnOXFqgKbiUgRaijviOd5IH97kDsejyA3TYOcw+EA8n6/R85yt5IkWT0fm4lIEWqwKaK87Hmeg5xlGXKqqgLZdV3k6Dr87t7vN3K+fW4NNhORItTYqP6tEMcxyJ/PBzmWZYF8v9+RE4YhyI/HAzmv1wvk2+22ej42E5Ei1GBTRPlCHIYB5KIokDNNE8jLpdU0/APQdR1y5HUQB9gUUb4QqcNmIlKEGlKEGlKEGlKEGj9Fm12J+dX0mgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABgUlEQVR4nO2XsaqCYBTH7XIDoUVBahHBJWhIXaVX6CncHXyPBjffQFpraOwhIhpSRBAsggaHwM27Cacz+HG50Lkf57f95D+cP8eDOOq6rlMk4OvTA/wVXIQaXIQaXIQa0hT5Fg0GQQA8iiKUqaoKuGVZKFOWJfD1eo0yp9MJuOM4g/NJsxEuQg3hGwnDELiu6yiT5znw2WyGMvP5HHgcxyijqipwvpH/CBehxkj0D/F6vQJPkgRl7vc78KIoUObxeACfTCYoM51OgR+Px8H5pNkIF6GG8AfxfD4D9zwPZd5vYrvdooymacBt20aZ1+slOlaPNBvhItSQpojwsT+fT+C32w1lVqsV8DRNUcYwDOBN06BM27aiY/VIsxEuQg3hGxmPx8Df33VFUZTFYgE8yzKUcV0X+OFwQJnlcik6Vo80G+Ei1JCmiPAf4jv7/R49M00T+OVyQZm6roH7vo8yu90O+GazGZxHmo1wEWr8+kaoIc1GuAg1uAg1uAg1uAg1fgCI8F4lQr/bHQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABhElEQVR4nO2ZscqCYBSGv35ycGgSWtPAockLcApy6Daa7CrcnIKEuoFoc3B3zQsQmsKlaHFwNxDUfxOOZ+gbfvgPH+fZHniH83I4qDjp+74XCvDz3wP8FVyEGlyEGlyEGsoUmcoGgyAAvtlsUKbrOuDH4xFl9vs98DzPUWa73QJ3HOfrfMpshItQQ/pGiqIA/vl8UMbzPOCapqFMlmXAXddFmcPhAPx6vX6dT5mNcBFqKFNE+th93weepinKhGEI/Ha7ocxsNgPeNA3KrNdr2bEGlNkIF6GG9I1cLhfglmWhzHw+Bz5+iRRCiLqugb/fb5R5Pp/Ad7vd1/mU2QgXoYYyRaSP3bZt4Pf7HWVOpxPw8/mMMo/HA7hpmigTx7HsWAPKbISLUEP6RhaLBfDxF6MQ+IGYJAnKrFYr4FVVoYyu67JjDSizES5CDWWKSB97WZbADcNAmdfrBXz8piuEEFEUAW/bFmWWy6XsWAPKbISLUGPC/9mJwUWowUWowUWowUWo8QvqTFxsTI3+/AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 40x40 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize weights as images\n",
        "def imshow(img):\n",
        "    plt.figure(figsize=(0.4, 0.4))\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Get the weights\n",
        "for name, param in net.named_parameters():\n",
        "    if 'weight' in name:\n",
        "        weights = param.data.cpu()\n",
        "        # Visualize the weights as images\n",
        "        if len(weights.size()) == 4:  # Convolutional layer\n",
        "            print(name)\n",
        "            for i in range(weights.size(0)):\n",
        "                for j in range(weights.size(1)):\n",
        "                  imshow(weights[i,j])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0_AEkXpmXpk"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5dgJ3hAtE7Z"
      },
      "source": [
        "## Let's play with some common pretrained deep nets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04DzkLKq1EaE"
      },
      "source": [
        "Resnets are a class of famous conv nets that worked accurately on a range os classification tasks.\n",
        "\n",
        "The key idea in resnet's was residual connections that enabled training of very deep networks.\n",
        "\n",
        "We shall see how the deeper a network, the better the accuracy at the cost of computation.\n",
        "\n",
        "A common theme in the 2016-18 times was to use pretrained features from Renset for various custom tasks on custom datasets.\n",
        "\n",
        "Your challenge would be to extract the last layer features from the resnet and train it on CIFAR 10 to improve performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JMnf8_6zCKs"
      },
      "source": [
        "### Pretrained models are trained with a specific image preprocessing.\n",
        "\n",
        "Hence, we must take care to preprocess the image the same way.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCtbIju2pGMF",
        "outputId": "81a8d050-663d-434d-91f7-b72412df9cd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/projectnb/ivc-ml/kmn5409/environments/sem/lib/python3.8/site-packages/torch/hub.py:365: UserWarning: TORCH_HUB is deprecated, please use env TORCH_HOME instead\n",
            "  warnings.warn('TORCH_HUB is deprecated, please use env TORCH_HOME instead')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ImageClassification(\n",
            "    crop_size=[224]\n",
            "    resize_size=[256]\n",
            "    mean=[0.485, 0.456, 0.406]\n",
            "    std=[0.229, 0.224, 0.225]\n",
            "    interpolation=InterpolationMode.BILINEAR\n",
            ")\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "weights = ResNet18_Weights.DEFAULT\n",
        "model = resnet18(weights=weights)\n",
        "model.eval()\n",
        "# Initialize the inference transforms\n",
        "preprocess = weights.transforms()\n",
        "print(preprocess)\n",
        "# Apply inference preprocessing transforms to the dataloaders\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                       download=True, transform=preprocess)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=preprocess)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAhtHTyN4Qyc"
      },
      "source": [
        "### However, there is a challenge.\n",
        "\n",
        "We cannot apply this network directly to CIFAR 10 for instance, since the output of the pretrained network is 1000 classes (for imagenet), and we only have 10 classes in CIFAR 10.\n",
        "\n",
        "Hence, we need to adapt it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmNLNg9K2YO8"
      },
      "source": [
        "## Challenge 1: Extract the last feature and train a net on top on CIFAR 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouUDSVvQZD9K",
        "outputId": "810c0a29-5092-460a-d8dc-08528eb00c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in /projectnb/ivc-ml/kmn5409/environments/sem/lib/python3.8/site-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHsg63jdpGMG",
        "outputId": "77b0210f-4db0-4779-997e-0821232b18f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /projectnb/ivc-ml/kmn5409/environments/sem/lib/python3.8/site-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfmkMftxYaWt",
        "outputId": "c5b31077-f426-4afc-9159-739e47d301d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/projectnb/ivc-ml/kmn5409/environments/sem/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/projectnb/ivc-ml/kmn5409/environments/sem/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,689,512\n",
            "Trainable params: 11,689,512\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 44.59\n",
            "Estimated Total Size (MB): 107.96\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "model1 = models.resnet18(pretrained=True).to(device)\n",
        "#model1.eval()\n",
        "summary(model1, input_size=(3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZqnLQn-2kmD",
        "outputId": "85f9da87-a76d-482e-9053-16733d924ba0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023it [00:09, 209.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 0.719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4022it [00:19, 214.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  4000] loss: 0.543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6024it [00:28, 215.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  6000] loss: 0.516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8028it [00:37, 213.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  8000] loss: 0.506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10030it [00:47, 214.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 10000] loss: 0.509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12029it [00:56, 214.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 12000] loss: 0.472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12500it [00:58, 212.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 84.48%\n",
            "Avg time taken for prediction: 0.0029301332473754883\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "newmodel = models.resnet18(pretrained=True).to(device)\n",
        "newmodel.eval()\n",
        "\n",
        "# step 1: make a new network that will replace the resnet head, you can add more layers if you like and compare the results\n",
        "out_dim = 512\n",
        "class MyNewResnet(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(MyNewResnet, self).__init__()\n",
        "        #Create a linear layer with the input being the output dimension size and the output size being the number of classes in CIFAR-10\n",
        "        self.fc3 = nn.\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "new_resnet = MyNewResnet().to(device)\n",
        "#This replaces the Resnet classification head with our fully connected layer\n",
        "newmodel.fc = new_resnet\n",
        "\n",
        "#Here we freeze the previous layers in ResNet and only update the parameters in the final fully connected layer\n",
        "for param in newmodel.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in newmodel.fc.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(newmodel.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# step 3: train this new network on CIFAR 10\n",
        "# Training the network\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in tqdm.tqdm(enumerate(trainloader, 0)):\n",
        "        # get the inputs\n",
        "        inputs, labels =\n",
        "        # zero the parameter gradients\n",
        "\n",
        "        # forward + backward + optimize\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "\n",
        "# step 4: test the accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "avg_time = []\n",
        "for data in testloader:\n",
        "    images, labels = data\n",
        "    start = time.time()\n",
        "    #outputs = newmodel(images.cuda())\n",
        "    outputs = newmodel(images.to(device))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    end = time.time()\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted.cpu() == labels).sum().item()\n",
        "    time_taken = end - start\n",
        "    avg_time.append(time_taken)\n",
        "\n",
        "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total}%\")\n",
        "print(f\"Avg time taken for prediction: {np.average(avg_time)}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here we are simply increasing the number of epochs to see if it improves performance"
      ],
      "metadata": {
        "id": "E34q79Ue2FnV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV8FP6af13QB",
        "outputId": "b2883a10-b466-493f-fc81-ecb68fd9824c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2030it [00:09, 220.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 0.718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4037it [00:19, 206.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  4000] loss: 0.546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6035it [00:28, 217.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  6000] loss: 0.520\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8035it [00:37, 214.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  8000] loss: 0.506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10040it [00:47, 215.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 10000] loss: 0.508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12028it [00:56, 217.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 12000] loss: 0.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12500it [00:58, 213.15it/s]\n",
            "2036it [00:10, 200.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2,  2000] loss: 0.454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4022it [00:19, 205.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2,  4000] loss: 0.470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6039it [00:29, 206.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2,  6000] loss: 0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8041it [00:39, 206.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2,  8000] loss: 0.465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10021it [00:48, 208.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 10000] loss: 0.472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12031it [00:58, 206.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 12000] loss: 0.442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12500it [01:00, 205.32it/s]\n",
            "2029it [00:09, 213.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3,  2000] loss: 0.433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4031it [00:19, 216.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3,  4000] loss: 0.452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6041it [00:28, 216.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3,  6000] loss: 0.447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8039it [00:37, 215.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3,  8000] loss: 0.450\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10023it [00:47, 214.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3, 10000] loss: 0.457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12033it [00:56, 218.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3, 12000] loss: 0.427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12500it [00:58, 212.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 85.42%\n",
            "Avg time taken for prediction: 0.0029567681312561035\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "newmodel = models.resnet18(pretrained=True).to(device)\n",
        "newmodel.eval()\n",
        "\n",
        "# step 1: make a new network that will replace the resnet head, you can add more layers if you like and compare the results\n",
        "out_dim = 512\n",
        "class MyNewResnet(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(MyNewResnet, self).__init__()\n",
        "\n",
        "        #Create a linear layer with the input being the output dimension size and the output size being the number of classes in CIFAR-10\n",
        "        self.fc3 = nn.\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "new_resnet = MyNewResnet().to(device)\n",
        "#This replaces the Resnet classification head with our fully connected layer\n",
        "newmodel.fc = new_resnet\n",
        "#print(new_resnet)\n",
        "for param in newmodel.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in newmodel.fc.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(newmodel.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# step 3: train this new network on CIFAR 10\n",
        "# Training the network\n",
        "for epoch in range(3):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in tqdm.tqdm(enumerate(trainloader, 0)):\n",
        "        # get the inputs\n",
        "        inputs, labels =\n",
        "        # zero the parameter gradients\n",
        "\n",
        "\n",
        "        # forward + backward + optimize\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "\n",
        "# step 4: test the accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "avg_time = []\n",
        "for data in testloader:\n",
        "    images, labels = data\n",
        "    start = time.time()\n",
        "    outputs = newmodel(images.to(device))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    end = time.time()\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted.cpu() == labels).sum().item()\n",
        "    time_taken = end - start\n",
        "    avg_time.append(time_taken)\n",
        "\n",
        "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total}%\")\n",
        "print(f\"Avg time taken for prediction: {np.average(avg_time)}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge : Repeat the same for ResNet 50 and observe the change in accuracy! :p"
      ],
      "metadata": {
        "id": "IjjZ_nB_Uyco"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn60KnCWr6nL"
      },
      "source": [
        "### Misc Notes:\n",
        "\n",
        "Fore more state-of-the art models, refer to Huggingface. https://huggingface.co/models\n",
        "\n",
        "https://www.cs.cmu.edu/~epxing/Class/10708-19/notes/lecture-16/ - CNN section.\n",
        "https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf - NeurIPS paper that showed feature hierarchy in CNN's.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}