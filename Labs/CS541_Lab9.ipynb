{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1dLwqvvHC9k"
      },
      "source": [
        "# CS541: Applied Machine Learning, Spring 2025, Lab 9\n",
        "\n",
        "\n",
        "Lab 9 is an exercise that explores Reinforcement Learning. In reinforcement learning, an agent learns to make decisions by interacting with an environment, it is used in robotics and other decision-making settings. Reinforcement learning works by having an agent interact with an environment and through trial-and-error is rewarded or punished based on certain actions. Based on the modeling on the environment the action can learn from it's environment but sometimes this may need to be adjusted to help the agent better learn.\n",
        "\n",
        "**Lab Grading**\n",
        "\n",
        "Labs are hands-on exercises designed to provide guided experience in key concepts through this class.  You are graded based on in-lab participation (not correctness), and **are required to submit** your lab work after class, before Friday of that week.  *Make sure you fill out the attendence form before leaving class*.\n",
        "\n",
        "For students who miss a lab, you can submit a make-up lab on gradescope by the Friday directly following the lab for partial credit.  Please see the syllabus for the lab grading policy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EEWHMbNufuB"
      },
      "source": [
        "Fun references for RL and Q Learning: http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture14.pdf\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7nZDqq2HZx5",
        "outputId": "f419d5d1-1a1a-4090-b955-bbc28e1d29da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [Connected to r2u.stat\u001b[0m\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "39 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+5build2).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.14).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.11/dist-packages (3.0)\n",
            "Requirement already satisfied: PyOpenGL in /usr/local/lib/python3.11/dist-packages (3.1.9)\n",
            "Requirement already satisfied: PyOpenGL-accelerate in /usr/local/lib/python3.11/dist-packages (3.1.9)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: xvfbwrapper in /usr/local/lib/python3.11/dist-packages (0.2.10)\n"
          ]
        }
      ],
      "source": [
        "!apt update\n",
        "!apt-get install -y xvfb ffmpeg x11-utils\n",
        "!pip install gym pyvirtualdisplay PyOpenGL PyOpenGL-accelerate\n",
        "!pip install xvfbwrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkicLSlZmDlr",
        "outputId": "28067266-8a7e-48df-b0c5-1c8536d90f94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.23.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEvn9FApG_Nx",
        "outputId": "696894f9-fa10-406b-86ba-0f38aa7ad611"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7e4bd6df89d0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "89-s1xk9L0cf"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import clear_output\n",
        "import imageio\n",
        "import base64\n",
        "import math\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DlubmKaXqUV"
      },
      "source": [
        "## Let's teach a machine to balance a cartpole\n",
        "\n",
        "https://www.gymlibrary.dev/environments/classic_control/cart_pole/\n",
        "\n",
        "<img src=\"https://www.gymlibrary.dev/_images/cart_pole.gif\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnVibeFvJifL",
        "outputId": "7d984bbe-2866-495b-9d37-04534684762a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.11/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "env = gym.make('CartPole-v1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHguxsdyz2ye"
      },
      "source": [
        "### We need to discretize the state space.\n",
        "\n",
        "Which means:\n",
        "\n",
        "Make a list of all possible states with possible values. Since angles can be continous and range from -infinity to +infinity, we need to define some coarse values to make it into a finite list.\n",
        "\n",
        "The funtion `discretize_state(observation, state_space)` does that for you.\n",
        "\n",
        "It takes in the environment (which is the cartpole simulator) and the current state, defined by 4 parameters:\n",
        "1. Cart Position: ranges from -4.8 to 4.8\n",
        "2. Cart Velocity: ranges from -Inf to Inf\n",
        "3. Pole Angle: ranges from  -0.418 rad (-24°) to 0.418 rad (24°)\n",
        "4. Pole Angular Velocity: -Inf to Inf\n",
        "\n",
        "Since we cannot have infinite values, we cap it to some min and max value.\n",
        "\n",
        "`discretize_state(observation, state_space)` will take in the 4 state space values, and turn it into an index in a flattened list indicating that state.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px78VhBTz4Vg",
        "outputId": "9a638f8c-814e-4d11-f143-38774aeaed96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Possible number of states : 810000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Discretize the state space\n",
        "# Example discretization: 30 bins for each of the 4 state values\n",
        "state_space = [30, 30, 30, 30]\n",
        "#Get the product of the state_space values\n",
        "state_space_size = np.prod(state_space)\n",
        "\n",
        "print(f\"Possible number of states : {state_space_size}\")\n",
        "\n",
        "\n",
        "# Define a simple method to discretize continuous state space\n",
        "def discretize_state(observation, state_space):\n",
        "\n",
        "    # For the upper_bounds let position 0 be the first highest value in the observation_space\n",
        "    # For the upper_bounds let position 1 be the third highest value in the observation_space\n",
        "    upper_bounds = [env.observation_space.high[0], 0.5, env.observation_space.high[2], math.radians(50)]\n",
        "    # For the lower bound let position 0 be the first lowest value in the observation_space\n",
        "    # For the lower bound let position 1 be the third lowest value in the observation_space\n",
        "    lower_bounds = [env.observation_space.low[0], -0.5, env.observation_space.low[2], -math.radians(50)]\n",
        "\n",
        "    # Let the ratios be the (observation at position i plus the absolute lower_bounds value at position i)\n",
        "    # We devide that by the (upper bounds at position i minus the lower bounds at position i)\n",
        "    ratios = [(observation[i] + abs(lower_bounds[i])) / (upper_bounds[i] - lower_bounds[i]) for i in range(len(observation))]\n",
        "    new_observation = [int(round((state_space[i] - 1) * ratios[i])) for i in range(len(observation))]\n",
        "    #print(new_observation)\n",
        "\n",
        "    # For the new observation we will get the minimum of the ( (state space at position i minus 1), max(0, new_observation[i]) )\n",
        "    new_observation = [min(state_space[i], max(0, new_observation[i])) for i in range(len(observation))]\n",
        "    #print(new_observation)\n",
        "    return tuple(new_observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkdODpmuMjuY",
        "outputId": "f98fc7a3-d9f6-4ce8-8007-25945dcc3a81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.0438494 ,  0.04746671, -0.00229842, -0.00876287], dtype=float32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.reset() # gives the initial start state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcHsPSuqnq5d"
      },
      "source": [
        "## Let's train the Q-learning agent.\n",
        "\n",
        "Play with the **`exploration_rate`, `exploration_decay_rate`**, and tweak the **`reward`** and see how the behavior changes.\n",
        "\n",
        "Sometimes, tricks as simple as training for longer (change **`episodes`**) can make a huge difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Grfogjo0Jg4Q"
      },
      "outputs": [],
      "source": [
        "class QLearningAgent:\n",
        "    def __init__(self, action_space, state_space, learning_rate=0.1, discount_factor=0.95, exploration_rate=1.0, exploration_decay_rate=0.9999995):\n",
        "        #Assign the corresponding args to the class instance variables\n",
        "        self.action_space = action_space\n",
        "        self.state_space = state_space\n",
        "        self.learning_rate = learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.exploration_rate = exploration_rate\n",
        "        self.exploration_decay_rate = exploration_decay_rate\n",
        "        # We define the q-table to a numpy array with zeros with number of rows being the state_space arg and the columns being the action_space\n",
        "        self.q_table = np.zeros((state_space, action_space))\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.uniform(0, 1) < self.exploration_rate:\n",
        "            #Randomly choose a element from the action_space using numpy\n",
        "            return np.random.choice(self.action_space)\n",
        "        else:\n",
        "            # Using numpy to get the argmax of the q-table at state position\n",
        "            return np.argmax(self.q_table[state])\n",
        "\n",
        "    def learn(self, state, action, reward, next_state, done):\n",
        "        # Get the element from the q-table at the row at the state position and the column at the action position\n",
        "        predict = self.q_table[state, action]\n",
        "        # The target is -0.5 if done else it is the reward plus the discount_factor multiplied by the np max value of the q-table at the next_state\n",
        "        target = -0.5 if done else reward + self.discount_factor * np.max(self.q_table[next_state])\n",
        "        # for the q-table value at the row at the state position and the column at the action position, we add that to the learning-rate multiplied by the (target minus the predict value)\n",
        "        self.q_table[state, action] += self.learning_rate * (target - predict)\n",
        "        if not done:\n",
        "            self.exploration_rate *= self.exploration_decay_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4VDlk-4JnCW",
        "outputId": "e68bef11-3088-42e1-a432-a0d922bb9e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 0, Exploration rate: 0.9998050185238566\n",
            "Episode: 100, Exploration rate: 0.9887487458827576\n",
            "Episode: 200, Exploration rate: 0.9788517739927698\n",
            "Episode: 300, Exploration rate: 0.9691410857478209\n",
            "Episode: 400, Exploration rate: 0.9592724907475046\n",
            "Episode: 500, Exploration rate: 0.9497560385663864\n",
            "Episode: 600, Exploration rate: 0.9402305629352153\n",
            "Episode: 700, Exploration rate: 0.9300330262779142\n",
            "Episode: 800, Exploration rate: 0.9201254973180569\n",
            "Episode: 900, Exploration rate: 0.9107332508509172\n",
            "Episode: 1000, Exploration rate: 0.9012025326999883\n",
            "Episode: 1100, Exploration rate: 0.8917670935545906\n",
            "Episode: 1200, Exploration rate: 0.8832735675804634\n",
            "Episode: 1300, Exploration rate: 0.8747734552113229\n",
            "Episode: 1400, Exploration rate: 0.8654805638480804\n",
            "Episode: 1500, Exploration rate: 0.8565476005420238\n",
            "Episode: 1600, Exploration rate: 0.8481307983031865\n",
            "Episode: 1700, Exploration rate: 0.839842893359229\n",
            "Episode: 1800, Exploration rate: 0.8314779813162706\n",
            "Episode: 1900, Exploration rate: 0.8233198735902972\n",
            "Episode: 2000, Exploration rate: 0.8147976228969379\n",
            "Episode: 2100, Exploration rate: 0.8071219267420752\n",
            "Episode: 2200, Exploration rate: 0.7993626471902581\n",
            "Episode: 2300, Exploration rate: 0.7911002461320547\n",
            "Episode: 2400, Exploration rate: 0.7830876787597191\n",
            "Episode: 2500, Exploration rate: 0.7754314957624221\n",
            "Episode: 2600, Exploration rate: 0.7674471500845392\n",
            "Episode: 2700, Exploration rate: 0.760118690865379\n",
            "Episode: 2800, Exploration rate: 0.7527698740882613\n",
            "Episode: 2900, Exploration rate: 0.7458500285681748\n",
            "Episode: 3000, Exploration rate: 0.7385283731749682\n",
            "Episode: 3100, Exploration rate: 0.7306828402547587\n",
            "Episode: 3200, Exploration rate: 0.7228664348305994\n",
            "Episode: 3300, Exploration rate: 0.7150549840379344\n",
            "Episode: 3400, Exploration rate: 0.7079294313220037\n",
            "Episode: 3500, Exploration rate: 0.7010080642485751\n",
            "Episode: 3600, Exploration rate: 0.6932282867055322\n",
            "Episode: 3700, Exploration rate: 0.6855588432227885\n",
            "Episode: 3800, Exploration rate: 0.6783099308251427\n",
            "Episode: 3900, Exploration rate: 0.6719166398096296\n",
            "Episode: 4000, Exploration rate: 0.6647621172003231\n",
            "Episode: 4100, Exploration rate: 0.6578153256989449\n",
            "Episode: 4200, Exploration rate: 0.6503620471322223\n",
            "Episode: 4300, Exploration rate: 0.6434080822698819\n",
            "Episode: 4400, Exploration rate: 0.6363693597159146\n",
            "Episode: 4500, Exploration rate: 0.6287942641032939\n",
            "Episode: 4600, Exploration rate: 0.6219185226361945\n",
            "Episode: 4700, Exploration rate: 0.6156102585425058\n",
            "Episode: 4800, Exploration rate: 0.6092106117342968\n",
            "Episode: 4900, Exploration rate: 0.6027629570572046\n",
            "Episode: 5000, Exploration rate: 0.5961003262969331\n",
            "Episode: 5100, Exploration rate: 0.5897914259218658\n",
            "Episode: 5200, Exploration rate: 0.5827940874383659\n",
            "Episode: 5300, Exploration rate: 0.5758480934121951\n",
            "Episode: 5400, Exploration rate: 0.5700299331860722\n",
            "Episode: 5500, Exploration rate: 0.5631318786200876\n",
            "Episode: 5600, Exploration rate: 0.5568544055414052\n",
            "Episode: 5700, Exploration rate: 0.5509829080772529\n",
            "Episode: 5800, Exploration rate: 0.5451133540249531\n",
            "Episode: 5900, Exploration rate: 0.539085256795255\n",
            "Episode: 6000, Exploration rate: 0.5331664725680961\n",
            "Episode: 6100, Exploration rate: 0.5262327860920231\n",
            "Episode: 6200, Exploration rate: 0.5197217867005957\n",
            "Episode: 6300, Exploration rate: 0.5128039504806693\n",
            "Episode: 6400, Exploration rate: 0.506036386160164\n",
            "Episode: 6500, Exploration rate: 0.49970780852147195\n",
            "Episode: 6600, Exploration rate: 0.49367801555053104\n",
            "Episode: 6700, Exploration rate: 0.48738213273961817\n",
            "Episode: 6800, Exploration rate: 0.48086109688395623\n",
            "Episode: 6900, Exploration rate: 0.4746123738527384\n",
            "Episode: 7000, Exploration rate: 0.46867444690531296\n",
            "Episode: 7100, Exploration rate: 0.46280386787928796\n",
            "Episode: 7200, Exploration rate: 0.4570365297447112\n",
            "Episode: 7300, Exploration rate: 0.4519462665698864\n",
            "Episode: 7400, Exploration rate: 0.44653521374754296\n",
            "Episode: 7500, Exploration rate: 0.4410566091022756\n",
            "Episode: 7600, Exploration rate: 0.4354426938007952\n",
            "Episode: 7700, Exploration rate: 0.4299797733808751\n",
            "Episode: 7800, Exploration rate: 0.4245217057675859\n",
            "Episode: 7900, Exploration rate: 0.4190051052830159\n",
            "Episode: 8000, Exploration rate: 0.41329146480307744\n",
            "Episode: 8100, Exploration rate: 0.4074825193993625\n",
            "Episode: 8200, Exploration rate: 0.40226175249719964\n",
            "Episode: 8300, Exploration rate: 0.3966534459100245\n",
            "Episode: 8400, Exploration rate: 0.3909082707376949\n",
            "Episode: 8500, Exploration rate: 0.3858304013152662\n",
            "Episode: 8600, Exploration rate: 0.3803446678487241\n",
            "Episode: 8700, Exploration rate: 0.3751206950694044\n",
            "Episode: 8800, Exploration rate: 0.3699296279678142\n",
            "Episode: 8900, Exploration rate: 0.365264869816961\n",
            "Episode: 9000, Exploration rate: 0.3599977296237151\n",
            "Episode: 9100, Exploration rate: 0.35523434254218\n",
            "Episode: 9200, Exploration rate: 0.3498563541032489\n",
            "Episode: 9300, Exploration rate: 0.3447786499732844\n",
            "Episode: 9400, Exploration rate: 0.33939770047639234\n",
            "Episode: 9500, Exploration rate: 0.33472441211294085\n",
            "Episode: 9600, Exploration rate: 0.33001645189353557\n",
            "Episode: 9700, Exploration rate: 0.3253909791805987\n",
            "Episode: 9800, Exploration rate: 0.3209009271775335\n",
            "Episode: 9900, Exploration rate: 0.31606800605814606\n",
            "Episode: 10000, Exploration rate: 0.31150405727881997\n",
            "Episode: 10100, Exploration rate: 0.30673136271950224\n",
            "Episode: 10200, Exploration rate: 0.3025502230198403\n",
            "Episode: 10300, Exploration rate: 0.29780152783755853\n",
            "Episode: 10400, Exploration rate: 0.29272751918875933\n",
            "Episode: 10500, Exploration rate: 0.2881402002769189\n",
            "Episode: 10600, Exploration rate: 0.283444724011602\n",
            "Episode: 10700, Exploration rate: 0.27926246935327004\n",
            "Episode: 10800, Exploration rate: 0.27476661081674647\n",
            "Episode: 10900, Exploration rate: 0.27026204032280976\n",
            "Episode: 11000, Exploration rate: 0.2661345397872227\n",
            "Episode: 11100, Exploration rate: 0.2619953958197862\n",
            "Episode: 11200, Exploration rate: 0.2569912100543027\n",
            "Episode: 11300, Exploration rate: 0.25259485437136364\n",
            "Episode: 11400, Exploration rate: 0.24748668633448065\n",
            "Episode: 11500, Exploration rate: 0.24311187865798187\n",
            "Episode: 11600, Exploration rate: 0.23863416692322376\n",
            "Episode: 11700, Exploration rate: 0.2339474803746071\n",
            "Episode: 11800, Exploration rate: 0.22939871388168484\n",
            "Episode: 11900, Exploration rate: 0.224972134872188\n",
            "Episode: 12000, Exploration rate: 0.22086165354155293\n",
            "Episode: 12100, Exploration rate: 0.21732772399727754\n",
            "Episode: 12200, Exploration rate: 0.21347215835777614\n",
            "Episode: 12300, Exploration rate: 0.20942619172987473\n",
            "Episode: 12400, Exploration rate: 0.20615665298392327\n",
            "Episode: 12500, Exploration rate: 0.20236870073309088\n",
            "Episode: 12600, Exploration rate: 0.19819992287538632\n",
            "Episode: 12700, Exploration rate: 0.19435690470221773\n",
            "Episode: 12800, Exploration rate: 0.19048265365325423\n",
            "Episode: 12900, Exploration rate: 0.1860640696356715\n",
            "Episode: 13000, Exploration rate: 0.18247004563501176\n",
            "Episode: 13100, Exploration rate: 0.17867097277128338\n",
            "Episode: 13200, Exploration rate: 0.174734192241083\n",
            "Episode: 13300, Exploration rate: 0.1715373233139297\n",
            "Episode: 13400, Exploration rate: 0.16812131321671792\n",
            "Episode: 13500, Exploration rate: 0.16472061069819802\n",
            "Episode: 13600, Exploration rate: 0.16139838010600632\n",
            "Episode: 13700, Exploration rate: 0.158095719241853\n",
            "Episode: 13800, Exploration rate: 0.15471978059357056\n",
            "Episode: 13900, Exploration rate: 0.15173955010396512\n",
            "Episode: 14000, Exploration rate: 0.1488368168265118\n",
            "Episode: 14100, Exploration rate: 0.14653810218143934\n",
            "Episode: 14200, Exploration rate: 0.14390673735389994\n",
            "Episode: 14300, Exploration rate: 0.14155175235493242\n",
            "Episode: 14400, Exploration rate: 0.13890223550827707\n",
            "Episode: 14500, Exploration rate: 0.13578262850104977\n",
            "Episode: 14600, Exploration rate: 0.13319180591404564\n",
            "Episode: 14700, Exploration rate: 0.1309080535951641\n",
            "Episode: 14800, Exploration rate: 0.12850015999113204\n",
            "Episode: 14900, Exploration rate: 0.12524916651084417\n",
            "Episode: 15000, Exploration rate: 0.12217812529109795\n",
            "Episode: 15100, Exploration rate: 0.11928552194720139\n",
            "Episode: 15200, Exploration rate: 0.11585969005830686\n",
            "Episode: 15300, Exploration rate: 0.11373427929014997\n",
            "Episode: 15400, Exploration rate: 0.11140807290256292\n",
            "Episode: 15500, Exploration rate: 0.10834815752031551\n",
            "Episode: 15600, Exploration rate: 0.10552624154113344\n",
            "Episode: 15700, Exploration rate: 0.10350652028677175\n",
            "Episode: 15800, Exploration rate: 0.10130335750419375\n",
            "Episode: 15900, Exploration rate: 0.09852146914197096\n",
            "Episode: 16000, Exploration rate: 0.09626688894996077\n",
            "Episode: 16100, Exploration rate: 0.09408036557646608\n",
            "Episode: 16200, Exploration rate: 0.09217549541329276\n",
            "Episode: 16300, Exploration rate: 0.0900895577421181\n",
            "Episode: 16400, Exploration rate: 0.08815654965738229\n",
            "Episode: 16500, Exploration rate: 0.08598640007157982\n",
            "Episode: 16600, Exploration rate: 0.08342425291435183\n",
            "Episode: 16700, Exploration rate: 0.08081672931165143\n",
            "Episode: 16800, Exploration rate: 0.07846823681204947\n",
            "Episode: 16900, Exploration rate: 0.07605135517657441\n",
            "Episode: 17000, Exploration rate: 0.07398584338212562\n",
            "Episode: 17100, Exploration rate: 0.07198146825885181\n",
            "Episode: 17200, Exploration rate: 0.0698792411930455\n",
            "Episode: 17300, Exploration rate: 0.06772047341708766\n",
            "Episode: 17400, Exploration rate: 0.06597649108004486\n",
            "Episode: 17500, Exploration rate: 0.06410699029557215\n",
            "Episode: 17600, Exploration rate: 0.062052656906193666\n",
            "Episode: 17700, Exploration rate: 0.059981023946481554\n",
            "Episode: 17800, Exploration rate: 0.057798518969053726\n",
            "Episode: 17900, Exploration rate: 0.05612116860552541\n",
            "Episode: 18000, Exploration rate: 0.054515115168813466\n",
            "Episode: 18100, Exploration rate: 0.05258957550901779\n",
            "Episode: 18200, Exploration rate: 0.051072328948053344\n",
            "Episode: 18300, Exploration rate: 0.04968423968143977\n",
            "Episode: 18400, Exploration rate: 0.04799768053004101\n",
            "Episode: 18500, Exploration rate: 0.04623456108661035\n",
            "Episode: 18600, Exploration rate: 0.04474087493164628\n",
            "Episode: 18700, Exploration rate: 0.043227091888446985\n",
            "Episode: 18800, Exploration rate: 0.04210903645205599\n",
            "Episode: 18900, Exploration rate: 0.040855942611732275\n",
            "Episode: 19000, Exploration rate: 0.03968535436795\n",
            "Episode: 19100, Exploration rate: 0.037932455796003094\n",
            "Episode: 19200, Exploration rate: 0.03633138583563456\n",
            "Episode: 19300, Exploration rate: 0.03522221226195454\n",
            "Episode: 19400, Exploration rate: 0.034250180809181255\n",
            "Episode: 19500, Exploration rate: 0.03337632376089372\n",
            "Episode: 19600, Exploration rate: 0.03254249311962945\n",
            "Episode: 19700, Exploration rate: 0.030921804682965452\n",
            "Episode: 19800, Exploration rate: 0.029717511620502648\n",
            "Episode: 19900, Exploration rate: 0.0286837683596081\n",
            "Episode: 20000, Exploration rate: 0.02765900379338224\n",
            "Episode: 20100, Exploration rate: 0.026406922551212308\n",
            "Episode: 20200, Exploration rate: 0.025405256386187406\n",
            "Episode: 20300, Exploration rate: 0.0242750963479572\n",
            "Episode: 20400, Exploration rate: 0.023501773872826277\n",
            "Episode: 20500, Exploration rate: 0.022839256478186496\n",
            "Episode: 20600, Exploration rate: 0.02205249490531442\n",
            "Episode: 20700, Exploration rate: 0.02126793740667347\n",
            "Episode: 20800, Exploration rate: 0.020402971433783383\n",
            "Episode: 20900, Exploration rate: 0.019887481924707122\n",
            "Episode: 21000, Exploration rate: 0.019279173251630144\n",
            "Episode: 21100, Exploration rate: 0.018445036253667925\n",
            "Episode: 21200, Exploration rate: 0.017781439791330293\n",
            "Episode: 21300, Exploration rate: 0.017013635224480725\n",
            "Episode: 21400, Exploration rate: 0.016352732283888755\n",
            "Episode: 21500, Exploration rate: 0.015763701188333607\n",
            "Episode: 21600, Exploration rate: 0.015151428300842599\n",
            "Episode: 21700, Exploration rate: 0.014750540670733761\n",
            "Episode: 21800, Exploration rate: 0.01393989114451622\n",
            "Episode: 21900, Exploration rate: 0.013433740687826828\n",
            "Episode: 22000, Exploration rate: 0.012810746452233046\n",
            "Episode: 22100, Exploration rate: 0.012323269301445896\n",
            "Episode: 22200, Exploration rate: 0.01182923708425197\n",
            "Episode: 22300, Exploration rate: 0.01143163029381922\n",
            "Episode: 22400, Exploration rate: 0.010962156199238871\n",
            "Episode: 22500, Exploration rate: 0.010570730463977973\n",
            "Episode: 22600, Exploration rate: 0.01021220750111246\n",
            "Episode: 22700, Exploration rate: 0.009814969491076922\n",
            "Episode: 22800, Exploration rate: 0.00952751230236476\n",
            "Episode: 22900, Exploration rate: 0.009201702838094418\n",
            "Episode: 23000, Exploration rate: 0.008844656214578837\n",
            "Episode: 23100, Exploration rate: 0.008548906448952632\n",
            "Episode: 23200, Exploration rate: 0.008155668902673644\n",
            "Episode: 23300, Exploration rate: 0.007791809689696024\n",
            "Episode: 23400, Exploration rate: 0.007540006620798761\n",
            "Episode: 23500, Exploration rate: 0.0071781230637078045\n",
            "Episode: 23600, Exploration rate: 0.00690446179769647\n",
            "Episode: 23700, Exploration rate: 0.006613696542407991\n",
            "Episode: 23800, Exploration rate: 0.006332009381343825\n",
            "Episode: 23900, Exploration rate: 0.006047757297973538\n",
            "Episode: 24000, Exploration rate: 0.00582746692365777\n",
            "Episode: 24100, Exploration rate: 0.005619919417853803\n",
            "Episode: 24200, Exploration rate: 0.005401610912931523\n",
            "Episode: 24300, Exploration rate: 0.005193366447323887\n",
            "Episode: 24400, Exploration rate: 0.004908713970732023\n",
            "Episode: 24500, Exploration rate: 0.004656396450708749\n",
            "Episode: 24600, Exploration rate: 0.004368683458770937\n",
            "Episode: 24700, Exploration rate: 0.004150096418622051\n",
            "Episode: 24800, Exploration rate: 0.003905717150202227\n",
            "Episode: 24900, Exploration rate: 0.0037273454279911945\n",
            "Episode: 25000, Exploration rate: 0.0036016108834328086\n",
            "Episode: 25100, Exploration rate: 0.0034278254802481735\n",
            "Episode: 25200, Exploration rate: 0.003289221748451637\n",
            "Episode: 25300, Exploration rate: 0.003200080345580086\n",
            "Episode: 25400, Exploration rate: 0.003038687832248391\n",
            "Episode: 25500, Exploration rate: 0.0028800298366588625\n",
            "Episode: 25600, Exploration rate: 0.002709273455225632\n",
            "Episode: 25700, Exploration rate: 0.002534940929928468\n",
            "Episode: 25800, Exploration rate: 0.002381356250946173\n",
            "Episode: 25900, Exploration rate: 0.002263008338327817\n",
            "Episode: 26000, Exploration rate: 0.0021410147796592145\n",
            "Episode: 26100, Exploration rate: 0.0020300080927862633\n",
            "Episode: 26200, Exploration rate: 0.0019442079523230883\n",
            "Episode: 26300, Exploration rate: 0.0018583882109789074\n",
            "Episode: 26400, Exploration rate: 0.0017884860197903934\n",
            "Episode: 26500, Exploration rate: 0.0017297197124132664\n",
            "Episode: 26600, Exploration rate: 0.0016433539605833604\n",
            "Episode: 26700, Exploration rate: 0.0015713798825381187\n",
            "Episode: 26800, Exploration rate: 0.0015137333944056366\n",
            "Episode: 26900, Exploration rate: 0.0014427397727976878\n",
            "Episode: 27000, Exploration rate: 0.0013901530278646232\n",
            "Episode: 27100, Exploration rate: 0.0013385992596364631\n",
            "Episode: 27200, Exploration rate: 0.00129347662695959\n",
            "Episode: 27300, Exploration rate: 0.001248014094333909\n",
            "Episode: 27400, Exploration rate: 0.0011974070891355168\n",
            "Episode: 27500, Exploration rate: 0.0011421338851329281\n",
            "Episode: 27600, Exploration rate: 0.001088475639412103\n",
            "Episode: 27700, Exploration rate: 0.0010320561643697753\n",
            "Episode: 27800, Exploration rate: 0.0009779105783492\n",
            "Episode: 27900, Exploration rate: 0.0009437470207841499\n",
            "Episode: 28000, Exploration rate: 0.0009189880116815286\n",
            "Episode: 28100, Exploration rate: 0.0008733775617650182\n",
            "Episode: 28200, Exploration rate: 0.0008249582734826028\n",
            "Episode: 28300, Exploration rate: 0.000790572764424066\n",
            "Episode: 28400, Exploration rate: 0.0007541132705979888\n",
            "Episode: 28500, Exploration rate: 0.0007184581531741838\n",
            "Episode: 28600, Exploration rate: 0.0006771869056074862\n",
            "Episode: 28700, Exploration rate: 0.0006426544539567827\n",
            "Episode: 28800, Exploration rate: 0.0006048630275346498\n",
            "Episode: 28900, Exploration rate: 0.0005685912878702695\n",
            "Episode: 29000, Exploration rate: 0.0005284201436281255\n",
            "Episode: 29100, Exploration rate: 0.0004978463746780461\n",
            "Episode: 29200, Exploration rate: 0.00046947798074432147\n",
            "Episode: 29300, Exploration rate: 0.00044814699028908046\n",
            "Episode: 29400, Exploration rate: 0.0004184369035389784\n",
            "Episode: 29500, Exploration rate: 0.00039472564920073604\n",
            "Episode: 29600, Exploration rate: 0.00037564172898968634\n",
            "Episode: 29700, Exploration rate: 0.00035555171267664064\n",
            "Episode: 29800, Exploration rate: 0.0003458968587329981\n",
            "Episode: 29900, Exploration rate: 0.00033536200393382144\n",
            "Episode: 30000, Exploration rate: 0.00031970076137169157\n",
            "Episode: 30100, Exploration rate: 0.0003037227593273749\n",
            "Episode: 30200, Exploration rate: 0.00028601954832421366\n",
            "Episode: 30300, Exploration rate: 0.0002691637707149575\n",
            "Episode: 30400, Exploration rate: 0.00025222330974736896\n",
            "Episode: 30500, Exploration rate: 0.00023796288101892693\n",
            "Episode: 30600, Exploration rate: 0.00022819821028557412\n",
            "Episode: 30700, Exploration rate: 0.00021861112956105227\n",
            "Episode: 30800, Exploration rate: 0.00021039977082716084\n",
            "Episode: 30900, Exploration rate: 0.00020173587383100376\n",
            "Episode: 31000, Exploration rate: 0.00019524480954885462\n",
            "Episode: 31100, Exploration rate: 0.00018687671011809038\n",
            "Episode: 31200, Exploration rate: 0.00017987892754444448\n",
            "Episode: 31300, Exploration rate: 0.00017137152811740964\n",
            "Episode: 31400, Exploration rate: 0.00016506738508706708\n",
            "Episode: 31500, Exploration rate: 0.00015822034958604526\n",
            "Episode: 31600, Exploration rate: 0.00015196398898741466\n",
            "Episode: 31700, Exploration rate: 0.00014551999064096887\n",
            "Episode: 31800, Exploration rate: 0.00013991825675416057\n",
            "Episode: 31900, Exploration rate: 0.00013341815955721594\n",
            "Episode: 32000, Exploration rate: 0.00012817328693960164\n",
            "Episode: 32100, Exploration rate: 0.00012277556882772986\n",
            "Episode: 32200, Exploration rate: 0.00011772106143181907\n",
            "Episode: 32300, Exploration rate: 0.00011292092961139108\n",
            "Episode: 32400, Exploration rate: 0.00010813146198382881\n",
            "Episode: 32500, Exploration rate: 0.00010292212188509882\n",
            "Episode: 32600, Exploration rate: 9.788247051773614e-05\n",
            "Episode: 32700, Exploration rate: 9.39833253744828e-05\n",
            "Episode: 32800, Exploration rate: 8.964139926604291e-05\n",
            "Episode: 32900, Exploration rate: 8.682001465771786e-05\n",
            "Episode: 33000, Exploration rate: 8.27548033263168e-05\n",
            "Episode: 33100, Exploration rate: 7.951669177246225e-05\n",
            "Episode: 33200, Exploration rate: 7.652916142436697e-05\n",
            "Episode: 33300, Exploration rate: 7.37142970052188e-05\n",
            "Episode: 33400, Exploration rate: 7.078496845649427e-05\n",
            "Episode: 33500, Exploration rate: 6.728595628075864e-05\n",
            "Episode: 33600, Exploration rate: 6.432616241812019e-05\n",
            "Episode: 33700, Exploration rate: 6.163447186144973e-05\n",
            "Episode: 33800, Exploration rate: 5.879231823639381e-05\n",
            "Episode: 33900, Exploration rate: 5.663380739081339e-05\n",
            "Episode: 34000, Exploration rate: 5.465583732088071e-05\n",
            "Episode: 34100, Exploration rate: 5.3176467227854334e-05\n",
            "Episode: 34200, Exploration rate: 5.160821567415653e-05\n",
            "Episode: 34300, Exploration rate: 4.982195698835913e-05\n",
            "Episode: 34400, Exploration rate: 4.7766792711737624e-05\n",
            "Episode: 34500, Exploration rate: 4.552404121214419e-05\n",
            "Episode: 34600, Exploration rate: 4.307963702836663e-05\n",
            "Episode: 34700, Exploration rate: 4.1539730708634615e-05\n",
            "Episode: 34800, Exploration rate: 3.9959651749951596e-05\n",
            "Episode: 34900, Exploration rate: 3.839472724742293e-05\n",
            "Episode: 35000, Exploration rate: 3.68975458041684e-05\n",
            "Episode: 35100, Exploration rate: 3.4707468227372576e-05\n",
            "Episode: 35200, Exploration rate: 3.2541126670463803e-05\n",
            "Episode: 35300, Exploration rate: 3.0813705938401056e-05\n",
            "Episode: 35400, Exploration rate: 2.8858062743024427e-05\n",
            "Episode: 35500, Exploration rate: 2.7093104995294797e-05\n",
            "Episode: 35600, Exploration rate: 2.558545751250196e-05\n",
            "Episode: 35700, Exploration rate: 2.394366928310279e-05\n",
            "Episode: 35800, Exploration rate: 2.2501428656580894e-05\n",
            "Episode: 35900, Exploration rate: 2.1118272150631255e-05\n",
            "Episode: 36000, Exploration rate: 1.9929748194085004e-05\n",
            "Episode: 36100, Exploration rate: 1.883983213407355e-05\n",
            "Episode: 36200, Exploration rate: 1.760720493997661e-05\n",
            "Episode: 36300, Exploration rate: 1.6459667941392957e-05\n",
            "Episode: 36400, Exploration rate: 1.533285396357159e-05\n",
            "Episode: 36500, Exploration rate: 1.446291371355805e-05\n",
            "Episode: 36600, Exploration rate: 1.3611874631457726e-05\n",
            "Episode: 36700, Exploration rate: 1.2928347973026738e-05\n",
            "Episode: 36800, Exploration rate: 1.2270981988507087e-05\n",
            "Episode: 36900, Exploration rate: 1.1660734355180396e-05\n",
            "Episode: 37000, Exploration rate: 1.1100465413208133e-05\n",
            "Episode: 37100, Exploration rate: 1.0600083953667286e-05\n",
            "Episode: 37200, Exploration rate: 1.0199123904068975e-05\n",
            "Episode: 37300, Exploration rate: 9.782516096900058e-06\n",
            "Episode: 37400, Exploration rate: 9.390669767132744e-06\n",
            "Episode: 37500, Exploration rate: 8.967944555144545e-06\n",
            "Episode: 37600, Exploration rate: 8.40764441945904e-06\n",
            "Episode: 37700, Exploration rate: 8.015372196614238e-06\n",
            "Episode: 37800, Exploration rate: 7.665050577212119e-06\n",
            "Episode: 37900, Exploration rate: 7.23572792522138e-06\n",
            "Episode: 38000, Exploration rate: 6.881804099172233e-06\n",
            "Episode: 38100, Exploration rate: 6.571556574430953e-06\n",
            "Episode: 38200, Exploration rate: 6.253214189168187e-06\n",
            "Episode: 38300, Exploration rate: 5.9125987867552675e-06\n",
            "Episode: 38400, Exploration rate: 5.5617082976305936e-06\n",
            "Episode: 38500, Exploration rate: 5.2189965407676415e-06\n",
            "Episode: 38600, Exploration rate: 4.97422723927917e-06\n",
            "Episode: 38700, Exploration rate: 4.724137009604554e-06\n",
            "Episode: 38800, Exploration rate: 4.436118327632279e-06\n",
            "Episode: 38900, Exploration rate: 4.211376751337499e-06\n",
            "Episode: 39000, Exploration rate: 3.941374214499056e-06\n",
            "Episode: 39100, Exploration rate: 3.681036157421469e-06\n",
            "Episode: 39200, Exploration rate: 3.451345365317098e-06\n",
            "Episode: 39300, Exploration rate: 3.2447683526923777e-06\n",
            "Episode: 39400, Exploration rate: 3.0449631607120996e-06\n",
            "Episode: 39500, Exploration rate: 2.9173442405357936e-06\n",
            "Episode: 39600, Exploration rate: 2.7786593800566383e-06\n",
            "Episode: 39700, Exploration rate: 2.6513221940605423e-06\n",
            "Episode: 39800, Exploration rate: 2.5191922865183127e-06\n",
            "Episode: 39900, Exploration rate: 2.391063386120032e-06\n"
          ]
        }
      ],
      "source": [
        "agent = QLearningAgent(env.action_space.n, state_space_size, exploration_rate=1.0, exploration_decay_rate=0.999995)\n",
        "\n",
        "def train_agent(episodes=40000):\n",
        "    for episode in range(episodes):\n",
        "        current_state = discretize_state(env.reset(), state_space)\n",
        "        current_state = np.prod(current_state)\n",
        "        #print(\"Current state\", current_state)\n",
        "        done = False\n",
        "        count=0\n",
        "        while not done:\n",
        "            count+=1\n",
        "            action = agent.choose_action(current_state)\n",
        "\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            ## Example of other things to tweak the reward\n",
        "            # angle = next_state[2]\n",
        "\n",
        "            next_state_discrete = discretize_state(next_state, state_space)\n",
        "            next_state_discrete_ind = np.prod(next_state_discrete)\n",
        "\n",
        "            agent.learn(current_state, action, reward, next_state_discrete_ind, done) # tweak the reward input here\n",
        "            current_state = next_state_discrete_ind\n",
        "\n",
        "        if episode % 100 == 0:\n",
        "            print(f\"Episode: {episode}, Exploration rate: {agent.exploration_rate}\")\n",
        "\n",
        "train_agent()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0-olF6SnlOq"
      },
      "source": [
        "## Now let's test the learned algorithm\n",
        "## We want to try and get the pole to balance for 120 frames\n",
        "## Maybe try and update the hyperparameters for the algorith to achieve this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "43Sa3JQyJp5Q",
        "outputId": "7d3c41f6-3b38-42b6-ec23-79bfdb3c77d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.11/dist-packages/imageio/plugins/pillow.py:409: DeprecationWarning: The keyword `fps` is no longer supported. Use `duration`(in ms) instead, e.g. `fps=50` == `duration=20` (1000 * 1/50).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJ9NJREFUeJzt3X9w1PWdx/HXhrALIeymAZJNJEEUBCIEFTDs2Xq0pASInpxxRi0HsWVg5BKnEEsxPapib4yHN+ePHsIf1xNvRkpLR/SkgsYg4azhhyk5fmlOGHrBkk1Qml2CEpLs5/5w2LmVqGwSsp9Nno+Z70z2+/ns7vv7mbB58fl+vt91GGOMAAAALJIQ6wIAAAC+jIACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKwT04Cyfv16XXvttRoyZIjy8vK0f//+WJYDAAAsEbOA8pvf/EZlZWV67LHH9Mc//lFTp05VQUGBmpubY1USAACwhCNWXxaYl5enGTNm6F//9V8lSaFQSFlZWXrooYf0yCOPxKIkAABgicRYvOnFixdVW1ur8vLy8L6EhATl5+erpqbmsv5tbW1qa2sLPw6FQjp79qxGjBghh8PRJzUDAICeMcbo3LlzyszMVELC15/EiUlA+eSTT9TZ2an09PSI/enp6frwww8v619RUaG1a9f2VXkAAOAqOnXqlEaPHv21fWISUKJVXl6usrKy8ONAIKDs7GydOnVKbrc7hpUBAIArFQwGlZWVpeHDh39j35gElJEjR2rQoEFqamqK2N/U1CSv13tZf5fLJZfLddl+t9tNQAEAIM5cyfKMmFzF43Q6NW3aNFVVVYX3hUIhVVVVyefzxaIkAABgkZid4ikrK1NxcbGmT5+uW2+9Vc8++6zOnz+vH/7wh7EqCQAAWCJmAeXee+/VmTNn9Oijj8rv9+umm27Szp07L1s4CwAABp6Y3QelJ4LBoDwejwKBAGtQAACIE9H8/ea7eAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArNPrAeXxxx+Xw+GI2CZOnBhuv3DhgkpKSjRixAglJyerqKhITU1NvV0GAACIY1dlBuXGG29UY2NjeHv33XfDbStXrtTrr7+urVu3qrq6WqdPn9bdd999NcoAAABxKvGqvGhiorxe72X7A4GAfvWrX2nz5s363ve+J0l68cUXNWnSJO3du1czZ868GuUAAIA4c1VmUD766CNlZmbquuuu08KFC9XQ0CBJqq2tVXt7u/Lz88N9J06cqOzsbNXU1Hzl67W1tSkYDEZsAACg/+r1gJKXl6dNmzZp586d2rBhg06ePKnvfOc7OnfunPx+v5xOp1JSUiKek56eLr/f/5WvWVFRIY/HE96ysrJ6u2wAAGCRXj/FM2/evPDPubm5ysvL05gxY/Tb3/5WQ4cO7dZrlpeXq6ysLPw4GAwSUgAA6Meu+mXGKSkpuuGGG3T8+HF5vV5dvHhRLS0tEX2ampq6XLNyicvlktvtjtgAAED/ddUDSmtrq06cOKGMjAxNmzZNgwcPVlVVVbi9vr5eDQ0N8vl8V7sUAAAQJ3r9FM9PfvIT3XnnnRozZoxOnz6txx57TIMGDdL9998vj8ejJUuWqKysTKmpqXK73XrooYfk8/m4ggcAAIT1ekD5+OOPdf/99+vTTz/VqFGj9O1vf1t79+7VqFGjJEnPPPOMEhISVFRUpLa2NhUUFOiFF17o7TIAAEAccxhjTKyLiFYwGJTH41EgEGA9CgAAcSKav998Fw8AALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDpRB5Q9e/bozjvvVGZmphwOh1599dWIdmOMHn30UWVkZGjo0KHKz8/XRx99FNHn7NmzWrhwodxut1JSUrRkyRK1trb26EAAAED/EXVAOX/+vKZOnar169d32b5u3To9//zz2rhxo/bt26dhw4apoKBAFy5cCPdZuHChjh49qsrKSm3fvl179uzRsmXLun8UAACgX3EYY0y3n+xwaNu2bVqwYIGkL2ZPMjMz9fDDD+snP/mJJCkQCCg9PV2bNm3Sfffdpw8++EA5OTk6cOCApk+fLknauXOn5s+fr48//liZmZnf+L7BYFAej0eBQEBut7u75QMAgD4Uzd/vXl2DcvLkSfn9fuXn54f3eTwe5eXlqaamRpJUU1OjlJSUcDiRpPz8fCUkJGjfvn1dvm5bW5uCwWDEBgAA+q9eDSh+v1+SlJ6eHrE/PT093Ob3+5WWlhbRnpiYqNTU1HCfL6uoqJDH4wlvWVlZvVk2AACwTFxcxVNeXq5AIBDeTp06FeuSAADAVdSrAcXr9UqSmpqaIvY3NTWF27xer5qbmyPaOzo6dPbs2XCfL3O5XHK73REbAADov3o1oIwdO1Zer1dVVVXhfcFgUPv27ZPP55Mk+Xw+tbS0qLa2Ntxn165dCoVCysvL681yAABAnEqM9gmtra06fvx4+PHJkydVV1en1NRUZWdna8WKFfrHf/xHjR8/XmPHjtXPf/5zZWZmhq/0mTRpkubOnaulS5dq48aNam9vV2lpqe67774ruoIHAAD0f1EHlPfff1/f/e53w4/LysokScXFxdq0aZN++tOf6vz581q2bJlaWlr07W9/Wzt37tSQIUPCz3n55ZdVWlqq2bNnKyEhQUVFRXr++ed74XAAAEB/0KP7oMQK90EBACD+xOw+KAAAAL2BgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDpRB5Q9e/bozjvvVGZmphwOh1599dWI9gceeEAOhyNimzt3bkSfs2fPauHChXK73UpJSdGSJUvU2traowMBAAD9R9QB5fz585o6darWr1//lX3mzp2rxsbG8PbrX/86on3hwoU6evSoKisrtX37du3Zs0fLli2LvnoAANAvJUb7hHnz5mnevHlf28flcsnr9XbZ9sEHH2jnzp06cOCApk+fLkn65S9/qfnz5+uf//mflZmZGW1JAACgn7kqa1B2796ttLQ0TZgwQcuXL9enn34abqupqVFKSko4nEhSfn6+EhIStG/fvi5fr62tTcFgMGIDAAD9V68HlLlz5+o//uM/VFVVpX/6p39SdXW15s2bp87OTkmS3+9XWlpaxHMSExOVmpoqv9/f5WtWVFTI4/GEt6ysrN4uGwAAWCTqUzzf5L777gv/PGXKFOXm5ur666/X7t27NXv27G69Znl5ucrKysKPg8EgIQUAgH7sql9mfN1112nkyJE6fvy4JMnr9aq5uTmiT0dHh86ePfuV61ZcLpfcbnfEBgAA+q+rHlA+/vhjffrpp8rIyJAk+Xw+tbS0qLa2Ntxn165dCoVCysvLu9rlAACAOBD1KZ7W1tbwbIgknTx5UnV1dUpNTVVqaqrWrl2roqIieb1enThxQj/96U81btw4FRQUSJImTZqkuXPnaunSpdq4caPa29tVWlqq++67jyt4AACAJMlhjDHRPGH37t367ne/e9n+4uJibdiwQQsWLNDBgwfV0tKizMxMzZkzR7/4xS+Unp4e7nv27FmVlpbq9ddfV0JCgoqKivT8888rOTn5imoIBoPyeDwKBAKc7gEAIE5E8/c76oBiAwIKAADxJ5q/33wXDwAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYJ+ovCwSA3mKM0fG3NsiEOr+233Xf+5ESXcP6qCoANiCgAIipwKkjMp0dX9sn1NEu4zRyOBx9VBWAWOMUDwDrxeF3mgLoIQIKAPuZUKwrANDHCCgA4gAzKMBAQ0ABYD1O8QADDwEFgP1CBBRgoCGgALCeEWtQgIGGgALAfpziAQYcAgoA67EGBRh4CCgA7EdAAQYcAgoA6xnugwIMOAQUAHGAGRRgoCGgALAea1CAgYeAAsB+BBRgwCGgALAfa1CAAYeAAsB6nOIBBh4CCgD7MYMCDDgEFADWYwYFGHgIKADsR0ABBpyoAkpFRYVmzJih4cOHKy0tTQsWLFB9fX1EnwsXLqikpEQjRoxQcnKyioqK1NTUFNGnoaFBhYWFSkpKUlpamlatWqWOjo6eHw2A/omAAgw4UQWU6upqlZSUaO/evaqsrFR7e7vmzJmj8+fPh/usXLlSr7/+urZu3arq6mqdPn1ad999d7i9s7NThYWFunjxot577z299NJL2rRpkx599NHeOyoA/Qp3kgUGHofpwcndM2fOKC0tTdXV1br99tsVCAQ0atQobd68Wffcc48k6cMPP9SkSZNUU1OjmTNnaseOHbrjjjt0+vRppaenS5I2btyo1atX68yZM3I6nd/4vsFgUB6PR4FAQG63u7vlA4gxY4xqf1Ui0/n1M6g3zP+x3KNz5HA4+qgyAFdDNH+/e7QGJRAISJJSU1MlSbW1tWpvb1d+fn64z8SJE5Wdna2amhpJUk1NjaZMmRIOJ5JUUFCgYDCoo0ePdvk+bW1tCgaDERuAgYNFssDA0+2AEgqFtGLFCt12222aPHmyJMnv98vpdColJSWib3p6uvx+f7jP/w8nl9ovtXWloqJCHo8nvGVlZXW3bABxiIACDDzdDiglJSU6cuSItmzZ0pv1dKm8vFyBQCC8nTp16qq/JwCLsAYFGHASu/Ok0tJSbd++XXv27NHo0aPD+71ery5evKiWlpaIWZSmpiZ5vd5wn/3790e83qWrfC71+TKXyyWXy9WdUgH0C8ygAANNVDMoxhiVlpZq27Zt2rVrl8aOHRvRPm3aNA0ePFhVVVXhffX19WpoaJDP55Mk+Xw+HT58WM3NzeE+lZWVcrvdysnJ6cmxAOinOMUDDDxRzaCUlJRo8+bNeu211zR8+PDwmhGPx6OhQ4fK4/FoyZIlKisrU2pqqtxutx566CH5fD7NnDlTkjRnzhzl5ORo0aJFWrdunfx+v9asWaOSkhJmSQB0jYACDDhRBZQNGzZIkmbNmhWx/8UXX9QDDzwgSXrmmWeUkJCgoqIitbW1qaCgQC+88EK476BBg7R9+3YtX75cPp9Pw4YNU3FxsZ544omeHQmAfov7oAADT4/ugxIr3AcF6B+u9D4o181eqtTrp3MfFCDO9dl9UACgTzCDAgw4BBQA1ovDiV4APURAAWA/Agow4BBQAFiPGRRg4CGgALAfa1CAAYeAAsB6zKAAAw8BBUAcYAYFGGgIKACsxwwKMPAQUADYj4ACDDgEFADW41b3wMBDQAEQB5hBAQYaAgoA+3GKBxhwCCgArMciWWDgIaAAsB9rUIABh4ACwHrMoAADDwEFgP0IKMCAQ0ABYD8CCjDgEFAAWI/7oAADDwEFQBxgBgUYaAgoAKzHIllg4CGgALAfAQUYcAgoAGJqeMYN39jn3On6PqgEgE0IKABiatjIMd/Y5/wnDX1QCQCbEFAAxJbDEesKAFiIgAIgthx8DAG4HJ8MAGLKwQwKgC4QUADEFgEFQBcIKABiihkUAF0hoACILdagAOgCnwwAYowZFACXI6AAiClO8QDoSlQBpaKiQjNmzNDw4cOVlpamBQsWqL4+8g6Ps2bNksPhiNgefPDBiD4NDQ0qLCxUUlKS0tLStGrVKnV0dPT8aADEHQeneAB0ITGaztXV1SopKdGMGTPU0dGhn/3sZ5ozZ46OHTumYcOGhfstXbpUTzzxRPhxUlJS+OfOzk4VFhbK6/XqvffeU2NjoxYvXqzBgwfrySef7IVDAhBXmEEB0IWoAsrOnTsjHm/atElpaWmqra3V7bffHt6flJQkr9fb5Wu89dZbOnbsmN5++22lp6frpptu0i9+8QutXr1ajz/+uJxOZzcOA0D8IqAAuFyP5lYDgYAkKTU1NWL/yy+/rJEjR2ry5MkqLy/XZ599Fm6rqanRlClTlJ6eHt5XUFCgYDCoo0ePdvk+bW1tCgaDERuA/oE1KAC6EtUMyv8XCoW0YsUK3XbbbZo8eXJ4/w9+8AONGTNGmZmZOnTokFavXq36+nq98sorkiS/3x8RTiSFH/v9/i7fq6KiQmvXru1uqQBsxhoUAF3odkApKSnRkSNH9O6770bsX7ZsWfjnKVOmKCMjQ7Nnz9aJEyd0/fXXd+u9ysvLVVZWFn4cDAaVlZXVvcIBWIUZFABd6dZ/XUpLS7V9+3a98847Gj169Nf2zcvLkyQdP35ckuT1etXU1BTR59Ljr1q34nK55Ha7IzYA/QQBBUAXogooxhiVlpZq27Zt2rVrl8aOHfuNz6mrq5MkZWRkSJJ8Pp8OHz6s5ubmcJ/Kykq53W7l5OREUw6AfsCRwCkeAJeL6hRPSUmJNm/erNdee03Dhw8PrxnxeDwaOnSoTpw4oc2bN2v+/PkaMWKEDh06pJUrV+r2229Xbm6uJGnOnDnKycnRokWLtG7dOvn9fq1Zs0YlJSVyuVy9f4QALMcMCoDLRfVflw0bNigQCGjWrFnKyMgIb7/5zW8kSU6nU2+//bbmzJmjiRMn6uGHH1ZRUZFef/318GsMGjRI27dv16BBg+Tz+fR3f/d3Wrx4ccR9UwAMIJziAdCFqGZQjDFf256VlaXq6upvfJ0xY8bojTfeiOatAfRT3EkWQFf4ZAAQW8ygAOgCAQVATHGZMYCuEFAAxBgBBcDlCCgAYoo1KAC6wicDgNjiFA+ALhBQAMQUa1AAdIWAAiDGCCgALkdAARBbrEEB0AU+GQDElCOBGRQAlyOgAIgt1qAA6AIBBUBMOViDAqALBBQAscUaFABd4JMBQGxxigdAFwgoAGKK+6AA6AoBBUBscYoHQBf4ZAAQU8ygAOgKAQVAjBFQAFyOgAIgpvg2YwBd4ZMBQGxxigdAFxJjXQCA+NbZ2SljTLefHwqFrvB9OtST00EJCQlKSOD/ZEC84F8rgB4pKirS0KFDu73lzZz5je9x4fPPlTQ0qUfvU1FR0QejAaC3MIMCoEc6OzvV0dHR7ee3t3/zc42k9h68h/RFnQDiBwEFQEyF/t/poZb2UfpLR7o6Qi45Ez7TSOefNWxQMIbVAYgVAgqAmLq0fuV02/U68dnN+qxzuEJK1CBHuz5uC2hy8h651BTjKgH0NdagAIipUEj65OI1Otr6HbV2piqkwZIc6jROBTtG6UCgUBdCw2JdJoA+RkABEFOfdw7VgeB8dRhnl+3tZoj2/OXePq4KQKwRUADE1BdrULgXCoBIBBQAMdWTe6gA6L8IKABiKhQioAC4HAEFQEwNdnymm4e/JYe6vk9Jgjp0W8orfVwVgFiLKqBs2LBBubm5crvdcrvd8vl82rFjR7j9woULKikp0YgRI5ScnKyioiI1NUVeHtjQ0KDCwkIlJSUpLS1Nq1at6tFNngDEN2OM0p1/0o3J72pIwjk51CHJKEHtSkoIKM+zXcMGtcS6TAB9LKr7oIwePVpPPfWUxo8fL2OMXnrpJd111106ePCgbrzxRq1cuVK///3vtXXrVnk8HpWWluruu+/WH/7wB0lf3MmxsLBQXq9X7733nhobG7V48WINHjxYTz755FU5QAB2u3CxQ6/94UNJH+ps+359cnG0LpohGpLQqnTnn/SXxL+oo+PKvq8HQP/hMD1coZaamqqnn35a99xzj0aNGqXNmzfrnnvukSR9+OGHmjRpkmpqajRz5kzt2LFDd9xxh06fPq309HRJ0saNG7V69WqdOXNGTmfXlxl+WTAYlMfj0QMPPHDFzwFwdezcuVMNDQ2xLuMbTZ8+XbfcckusywAGtIsXL2rTpk0KBAJyu91f27fbd5Lt7OzU1q1bdf78efl8PtXW1qq9vV35+fnhPhMnTlR2dnY4oNTU1GjKlCnhcCJJBQUFWr58uY4ePaqbb765y/dqa2tTW1tb+HEw+MWtrxctWqTk5OTuHgKAXnDs2LG4CCi33HKLlixZEusygAGttbVVmzZtuqK+UQeUw4cPy+fz6cKFC0pOTta2bduUk5Ojuro6OZ1OpaSkRPRPT0+X3++XJPn9/ohwcqn9UttXqaio0Nq1ay/bP3369G9MYACuri//m7fVNddco1tvvTXWZQAD2qUJhisR9VU8EyZMUF1dnfbt26fly5eruLhYx44di/ZlolJeXq5AIBDeTp06dVXfDwAAxFbUMyhOp1Pjxo2TJE2bNk0HDhzQc889p3vvvVcXL15US0tLxP+ompqa5PV6JUler1f79++PeL1LV/lc6tMVl8sll8sVbakAACBO9fg+KKFQSG1tbZo2bZoGDx6sqqqqcFt9fb0aGhrk8/kkST6fT4cPH1Zzc3O4T2Vlpdxut3JycnpaCgAA6CeimkEpLy/XvHnzlJ2drXPnzmnz5s3avXu33nzzTXk8Hi1ZskRlZWVKTU2V2+3WQw89JJ/Pp5kzZ0qS5syZo5ycHC1atEjr1q2T3+/XmjVrVFJSwgwJAAAIiyqgNDc3a/HixWpsbJTH41Fubq7efPNNff/735ckPfPMM0pISFBRUZHa2tpUUFCgF154Ifz8QYMGafv27Vq+fLl8Pp+GDRum4uJiPfHEE717VAAAIK5FFVB+9atffW37kCFDtH79eq1fv/4r+4wZM0ZvvPFGNG8LAAAGGL6LBwAAWIeAAgAArENAAQAA1iGgAAAA63T7u3gAQJJmzpypxET7P0omTpwY6xIARKHH32YcC5e+zfhKvg0RAADYIZq/35ziAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArBNVQNmwYYNyc3Pldrvldrvl8/m0Y8eOcPusWbPkcDgitgcffDDiNRoaGlRYWKikpCSlpaVp1apV6ujo6J2jAQAA/UJiNJ1Hjx6tp556SuPHj5cxRi+99JLuuusuHTx4UDfeeKMkaenSpXriiSfCz0lKSgr/3NnZqcLCQnm9Xr333ntqbGzU4sWLNXjwYD355JO9dEgAACDeOYwxpicvkJqaqqefflpLlizRrFmzdNNNN+nZZ5/tsu+OHTt0xx136PTp00pPT5ckbdy4UatXr9aZM2fkdDqv6D2DwaA8Ho8CgYDcbndPygcAAH0kmr/f3V6D0tnZqS1btuj8+fPy+Xzh/S+//LJGjhypyZMnq7y8XJ999lm4raamRlOmTAmHE0kqKChQMBjU0aNHv/K92traFAwGIzYAANB/RXWKR5IOHz4sn8+nCxcuKDk5Wdu2bVNOTo4k6Qc/+IHGjBmjzMxMHTp0SKtXr1Z9fb1eeeUVSZLf748IJ5LCj/1+/1e+Z0VFhdauXRttqQAAIE5FHVAmTJiguro6BQIB/e53v1NxcbGqq6uVk5OjZcuWhftNmTJFGRkZmj17tk6cOKHrr7++20WWl5errKws/DgYDCorK6vbrwcAAOwW9Skep9OpcePGadq0aaqoqNDUqVP13HPPddk3Ly9PknT8+HFJktfrVVNTU0SfS4+9Xu9XvqfL5QpfOXRpAwAA/VeP74MSCoXU1tbWZVtdXZ0kKSMjQ5Lk8/l0+PBhNTc3h/tUVlbK7XaHTxMBAABEdYqnvLxc8+bNU3Z2ts6dO6fNmzdr9+7devPNN3XixAlt3rxZ8+fP14gRI3To0CGtXLlSt99+u3JzcyVJc+bMUU5OjhYtWqR169bJ7/drzZo1KikpkcvluioHCAAA4k9UAaW5uVmLFy9WY2OjPB6PcnNz9eabb+r73/++Tp06pbffflvPPvuszp8/r6ysLBUVFWnNmjXh5w8aNEjbt2/X8uXL5fP5NGzYMBUXF0fcNwUAAKDH90GJBe6DAgBA/OmT+6AAAABcLQQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6ibEuoDuMMZKkYDAY40oAAMCVuvR3+9Lf8a8TlwHl3LlzkqSsrKwYVwIAAKJ17tw5eTyer+3jMFcSYywTCoVUX1+vnJwcnTp1Sm63O9Ylxa1gMKisrCzGsRcwlr2HsewdjGPvYSx7hzFG586dU2ZmphISvn6VSVzOoCQkJOiaa66RJLndbn5ZegHj2HsYy97DWPYOxrH3MJY9900zJ5ewSBYAAFiHgAIAAKwTtwHF5XLpsccek8vlinUpcY1x7D2MZe9hLHsH49h7GMu+F5eLZAEAQP8WtzMoAACg/yKgAAAA6xBQAACAdQgoAADAOnEZUNavX69rr71WQ4YMUV5envbv3x/rkqyzZ88e3XnnncrMzJTD4dCrr74a0W6M0aOPPqqMjAwNHTpU+fn5+uijjyL6nD17VgsXLpTb7VZKSoqWLFmi1tbWPjyK2KuoqNCMGTM0fPhwpaWlacGCBaqvr4/oc+HCBZWUlGjEiBFKTk5WUVGRmpqaIvo0NDSosLBQSUlJSktL06pVq9TR0dGXhxJTGzZsUG5ubvgmVz6fTzt27Ai3M4bd99RTT8nhcGjFihXhfYznlXn88cflcDgitokTJ4bbGccYM3Fmy5Ytxul0mn//9383R48eNUuXLjUpKSmmqakp1qVZ5Y033jD/8A//YF555RUjyWzbti2i/amnnjIej8e8+uqr5r//+7/N3/zN35ixY8eazz//PNxn7ty5ZurUqWbv3r3mv/7rv8y4cePM/fff38dHElsFBQXmxRdfNEeOHDF1dXVm/vz5Jjs727S2tob7PPjggyYrK8tUVVWZ999/38ycOdP81V/9Vbi9o6PDTJ482eTn55uDBw+aN954w4wcOdKUl5fH4pBi4j//8z/N73//e/M///M/pr6+3vzsZz8zgwcPNkeOHDHGMIbdtX//fnPttdea3Nxc8+Mf/zi8n/G8Mo899pi58cYbTWNjY3g7c+ZMuJ1xjK24Cyi33nqrKSkpCT/u7Ow0mZmZpqKiIoZV2e3LASUUChmv12uefvrp8L6WlhbjcrnMr3/9a2OMMceOHTOSzIEDB8J9duzYYRwOh/nzn//cZ7Xbprm52Ugy1dXVxpgvxm3w4MFm69at4T4ffPCBkWRqamqMMV+ExYSEBOP3+8N9NmzYYNxut2lra+vbA7DIt771LfNv//ZvjGE3nTt3zowfP95UVlaav/7rvw4HFMbzyj322GNm6tSpXbYxjrEXV6d4Ll68qNraWuXn54f3JSQkKD8/XzU1NTGsLL6cPHlSfr8/Yhw9Ho/y8vLC41hTU6OUlBRNnz493Cc/P18JCQnat29fn9dsi0AgIElKTU2VJNXW1qq9vT1iLCdOnKjs7OyIsZwyZYrS09PDfQoKChQMBnX06NE+rN4OnZ2d2rJli86fPy+fz8cYdlNJSYkKCwsjxk3idzJaH330kTIzM3Xddddp4cKFamhokMQ42iCuvizwk08+UWdnZ8QvgySlp6frww8/jFFV8cfv90tSl+N4qc3v9ystLS2iPTExUampqeE+A00oFNKKFSt02223afLkyZK+GCen06mUlJSIvl8ey67G+lLbQHH48GH5fD5duHBBycnJ2rZtm3JyclRXV8cYRmnLli364x//qAMHDlzWxu/klcvLy9OmTZs0YcIENTY2au3atfrOd76jI0eOMI4WiKuAAsRSSUmJjhw5onfffTfWpcSlCRMmqK6uToFAQL/73e9UXFys6urqWJcVd06dOqUf//jHqqys1JAhQ2JdTlybN29e+Ofc3Fzl5eVpzJgx+u1vf6uhQ4fGsDJIcXYVz8iRIzVo0KDLVlE3NTXJ6/XGqKr4c2msvm4cvV6vmpubI9o7Ojp09uzZATnWpaWl2r59u9555x2NHj06vN/r9erixYtqaWmJ6P/lsexqrC+1DRROp1Pjxo3TtGnTVFFRoalTp+q5555jDKNUW1ur5uZm3XLLLUpMTFRiYqKqq6v1/PPPKzExUenp6YxnN6WkpOiGG27Q8ePH+b20QFwFFKfTqWnTpqmqqiq8LxQKqaqqSj6fL4aVxZexY8fK6/VGjGMwGNS+ffvC4+jz+dTS0qLa2tpwn127dikUCikvL6/Pa44VY4xKS0u1bds27dq1S2PHjo1onzZtmgYPHhwxlvX19WpoaIgYy8OHD0cEvsrKSrndbuXk5PTNgVgoFAqpra2NMYzS7NmzdfjwYdXV1YW36dOna+HCheGfGc/uaW1t1YkTJ5SRkcHvpQ1ivUo3Wlu2bDEul8ts2rTJHDt2zCxbtsykpKRErKLGFyv8Dx48aA4ePGgkmX/5l38xBw8eNP/7v/9rjPniMuOUlBTz2muvmUOHDpm77rqry8uMb775ZrNv3z7z7rvvmvHjxw+4y4yXL19uPB6P2b17d8SliJ999lm4z4MPPmiys7PNrl27zPvvv298Pp/x+Xzh9kuXIs6ZM8fU1dWZnTt3mlGjRg2oSxEfeeQRU11dbU6ePGkOHTpkHnnkEeNwOMxbb71ljGEMe+r/X8VjDON5pR5++GGze/duc/LkSfOHP/zB5Ofnm5EjR5rm5mZjDOMYa3EXUIwx5pe//KXJzs42TqfT3HrrrWbv3r2xLsk677zzjpF02VZcXGyM+eJS45///OcmPT3duFwuM3v2bFNfXx/xGp9++qm5//77TXJysnG73eaHP/yhOXfuXAyOJna6GkNJ5sUXXwz3+fzzz83f//3fm29961smKSnJ/O3f/q1pbGyMeJ0//elPZt68eWbo0KFm5MiR5uGHHzbt7e19fDSx86Mf/ciMGTPGOJ1OM2rUKDN79uxwODGGMeypLwcUxvPK3HvvvSYjI8M4nU5zzTXXmHvvvdccP3483M44xpbDGGNiM3cDAADQtbhagwIAAAYGAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArPN/GN50hd+LGt4AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "frames = []\n",
        "env.close()  # Close the previous env\n",
        "env = gym.make('CartPole-v1')  # Re-make the environment\n",
        "\n",
        "state = discretize_state(env.reset(), state_space)\n",
        "state = np.prod(state)\n",
        "img = plt.imshow(env.render(mode='rgb_array')) # only call this once, only for the first frame\n",
        "done = False\n",
        "while not done:\n",
        "    frame = env.render(mode='rgb_array')\n",
        "    frames.append(frame)\n",
        "    action = agent.choose_action(state)\n",
        "    next_state, reward, done, info = env.step(action)\n",
        "    state = discretize_state(next_state, state_space)\n",
        "    state = np.prod(state)\n",
        "\n",
        "env.close()\n",
        "\n",
        "# Save frames as video\n",
        "imageio.mimsave('cartpole-v1.gif', frames, 'GIF', fps=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P4xcuuLm31T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
